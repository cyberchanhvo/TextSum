{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T12:06:46.761118Z",
     "start_time": "2021-07-20T12:06:44.413368Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-extractive-summarizer in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bert-extractive-summarizer) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bert-extractive-summarizer) (0.24.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bert-extractive-summarizer) (4.8.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.19.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.8.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from spacy->bert-extractive-summarizer) (3.7.4.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (47.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (4.61.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (21.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.7.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (8.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from catalogue<2.1.0,>=2.0.4->spacy->bert-extractive-summarizer) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from packaging>=20.0->spacy->bert-extractive-summarizer) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pathy>=0.3.5->spacy->bert-extractive-summarizer) (5.1.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (1.26.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy->bert-extractive-summarizer) (0.4.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy->bert-extractive-summarizer) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jinja2->spacy->bert-extractive-summarizer) (2.0.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers->bert-extractive-summarizer) (0.0.45)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers->bert-extractive-summarizer) (2021.7.6)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers->bert-extractive-summarizer) (0.10.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers->bert-extractive-summarizer) (3.0.12)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers->bert-extractive-summarizer) (3.10.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers->bert-extractive-summarizer) (0.0.12)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers->bert-extractive-summarizer) (5.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from sacremoses->transformers->bert-extractive-summarizer) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install werkzeug\n",
    "!pip install bert-extractive-summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T12:07:22.516928Z",
     "start_time": "2021-07-20T12:07:05.004551Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter-client==6.1.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (6.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-client==6.1.5) (2.8.2)\n",
      "Requirement already satisfied: tornado>=4.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-client==6.1.5) (6.1)\n",
      "Requirement already satisfied: traitlets in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-client==6.1.5) (5.0.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-client==6.1.5) (4.7.1)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-client==6.1.5) (22.1.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client==6.1.5) (301)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.1->jupyter-client==6.1.5) (1.15.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from traitlets->jupyter-client==6.1.5) (0.2.0)\n",
      "Requirement already satisfied: wrapt==1.12.1 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (1.12.1)\n",
      "Requirement already satisfied: traitlets==5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from traitlets==5.0) (0.2.0)\n",
      "Requirement already satisfied: typed-ast in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: pytest-filter-subpackage in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: pytest>=3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest-filter-subpackage) (6.2.4)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=3.0->pytest-filter-subpackage) (1.10.0)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=3.0->pytest-filter-subpackage) (0.13.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=3.0->pytest-filter-subpackage) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=3.0->pytest-filter-subpackage) (21.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=3.0->pytest-filter-subpackage) (3.10.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=3.0->pytest-filter-subpackage) (0.4.4)\n",
      "Requirement already satisfied: toml in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=3.0->pytest-filter-subpackage) (0.10.2)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=3.0->pytest-filter-subpackage) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=3.0->pytest-filter-subpackage) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata>=0.12->pytest>=3.0->pytest-filter-subpackage) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata>=0.12->pytest>=3.0->pytest-filter-subpackage) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from packaging->pytest>=3.0->pytest-filter-subpackage) (2.4.7)\n",
      "Requirement already satisfied: pytest-cov in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.12.1)\n",
      "Requirement already satisfied: toml in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest-cov) (0.10.2)\n",
      "Requirement already satisfied: coverage>=5.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest-cov) (5.5)\n",
      "Requirement already satisfied: pytest>=4.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest-cov) (6.2.4)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=4.6->pytest-cov) (0.13.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=4.6->pytest-cov) (0.4.4)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=4.6->pytest-cov) (1.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=4.6->pytest-cov) (21.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=4.6->pytest-cov) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=4.6->pytest-cov) (21.2.0)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=4.6->pytest-cov) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest>=4.6->pytest-cov) (3.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata>=0.12->pytest>=4.6->pytest-cov) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata>=0.12->pytest>=4.6->pytest-cov) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from packaging->pytest>=4.6->pytest-cov) (2.4.7)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (2.5.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (47.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard~=2.5->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard~=2.5->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.10.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvi in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pyvi) (0.3.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pyvi) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->pyvi) (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->pyvi) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn->pyvi) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->pyvi) (1.0.1)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sklearn-crfsuite->pyvi) (4.61.2)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tqdm>=2.0->sklearn-crfsuite->pyvi) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyter-client==6.1.5\n",
    "!pip install wrapt==1.12.1\n",
    "!pip install traitlets==5.0\n",
    "!pip install typed-ast\n",
    "!pip install pytest-filter-subpackage\n",
    "!pip install pytest-cov\n",
    "!pip install tensorflow --user\n",
    "!pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T12:10:07.382630Z",
     "start_time": "2021-07-20T12:07:37.944857Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
      "Collecting torch\n",
      "  Downloading torch-1.9.0-cp37-cp37m-win_amd64.whl (222.0 MB)\n",
      "Collecting spacy==2.1.3\n",
      "  Downloading spacy-2.1.3-cp37-cp37m-win_amd64.whl (26.9 MB)\n",
      "Collecting transformers==3.3.0\n",
      "  Using cached transformers-3.3.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-win_amd64.whl (1.1 MB)\n",
      "Collecting Cython\n",
      "  Downloading Cython-0.29.24-cp37-cp37m-win_amd64.whl (1.6 MB)\n",
      "Collecting tqdm==4.32.2\n",
      "  Downloading tqdm-4.32.2-py2.py3-none-any.whl (50 kB)\n",
      "Collecting neuralcoref\n",
      "  Downloading neuralcoref-4.0-cp37-cp37m-win_amd64.whl (227 kB)\n",
      "Collecting argparse\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from -r requirements.txt (line 10)) (0.24.2)\n",
      "Requirement already satisfied: pytest in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from -r requirements.txt (line 11)) (6.2.4)\n",
      "Collecting blis<0.3.0,>=0.2.2\n",
      "  Downloading blis-0.2.4-cp37-cp37m-win_amd64.whl (3.1 MB)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.1.3->-r requirements.txt (line 3)) (2.0.5)\n",
      "Collecting plac<1.0.0,>=0.9.6\n",
      "  Using cached plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.1.3->-r requirements.txt (line 3)) (0.8.2)\n",
      "Collecting srsly<1.1.0,>=0.0.5\n",
      "  Downloading srsly-1.0.5-cp37-cp37m-win_amd64.whl (176 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.1.3->-r requirements.txt (line 3)) (2.26.0)\n",
      "Collecting preshed<2.1.0,>=2.0.1\n",
      "  Downloading preshed-2.0.1-cp37-cp37m-win_amd64.whl (73 kB)\n",
      "Collecting jsonschema<3.0.0,>=2.6.0\n",
      "  Downloading jsonschema-2.6.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting thinc<7.1.0,>=7.0.2\n",
      "  Downloading thinc-7.0.8-cp37-cp37m-win_amd64.whl (1.9 MB)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy==2.1.3->-r requirements.txt (line 3)) (1.0.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers==3.3.0->-r requirements.txt (line 4)) (2021.7.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers==3.3.0->-r requirements.txt (line 4)) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers==3.3.0->-r requirements.txt (line 4)) (0.0.45)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-win_amd64.whl (1.9 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers==3.3.0->-r requirements.txt (line 4)) (21.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3->-r requirements.txt (line 3)) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3->-r requirements.txt (line 3)) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3->-r requirements.txt (line 3)) (2.0.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.3->-r requirements.txt (line 3)) (1.26.6)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from torch->-r requirements.txt (line 2)) (3.7.4.3)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.18.2-py3-none-any.whl (131 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 10)) (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 10)) (2.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest->-r requirements.txt (line 11)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest->-r requirements.txt (line 11)) (21.2.0)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest->-r requirements.txt (line 11)) (1.10.0)\n",
      "Requirement already satisfied: toml in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest->-r requirements.txt (line 11)) (0.10.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest->-r requirements.txt (line 11)) (3.10.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest->-r requirements.txt (line 11)) (0.4.4)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest->-r requirements.txt (line 11)) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytest->-r requirements.txt (line 11)) (0.13.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata>=0.12->pytest->-r requirements.txt (line 11)) (3.5.0)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.22.0,>=1.21.2\n",
      "  Downloading botocore-1.21.2-py3-none-any.whl (7.7 MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from botocore<1.22.0,>=1.21.2->boto3->neuralcoref->-r requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.2->boto3->neuralcoref->-r requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from packaging->transformers==3.3.0->-r requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sacremoses->transformers==3.3.0->-r requirements.txt (line 4)) (7.1.2)\n",
      "Installing collected packages: jmespath, tqdm, srsly, preshed, plac, botocore, blis, thinc, s3transfer, jsonschema, tokenizers, spacy, sentencepiece, boto3, transformers, torch, neuralcoref, Cython, argparse\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.61.2\n",
      "    Uninstalling tqdm-4.61.2:\n",
      "      Successfully uninstalled tqdm-4.61.2\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 2.4.1\n",
      "    Uninstalling srsly-2.4.1:\n",
      "      Successfully uninstalled srsly-2.4.1\n",
      "  Attempting uninstall: preshed\n",
      "    Found existing installation: preshed 3.0.5\n",
      "    Uninstalling preshed-3.0.5:\n",
      "      Successfully uninstalled preshed-3.0.5\n",
      "  Attempting uninstall: blis\n",
      "    Found existing installation: blis 0.7.4\n",
      "    Uninstalling blis-0.7.4:\n",
      "      Successfully uninstalled blis-0.7.4\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.0.8\n",
      "    Uninstalling thinc-8.0.8:\n",
      "      Successfully uninstalled thinc-8.0.8\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 3.2.0\n",
      "    Uninstalling jsonschema-3.2.0:\n",
      "      Successfully uninstalled jsonschema-3.2.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.1.1\n",
      "    Uninstalling spacy-3.1.1:\n",
      "      Successfully uninstalled spacy-3.1.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.8.2\n",
      "    Uninstalling transformers-4.8.2:\n",
      "      Successfully uninstalled transformers-4.8.2\n",
      "Successfully installed Cython-0.29.24 argparse-1.4.0 blis-0.2.4 boto3-1.18.2 botocore-1.21.2 jmespath-0.10.0 jsonschema-2.6.0 neuralcoref-4.0 plac-0.9.6 preshed-2.0.1 s3transfer-0.5.0 sentencepiece-0.1.96 spacy-2.1.3 srsly-1.0.5 thinc-7.0.8 tokenizers-0.8.1rc2 torch-1.9.0 tqdm-4.32.2 transformers-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T12:10:30.802284Z",
     "start_time": "2021-07-20T12:10:28.600146Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neuralcoref in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from neuralcoref) (1.19.5)\n",
      "Requirement already satisfied: boto3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from neuralcoref) (1.18.2)\n",
      "Requirement already satisfied: spacy>=2.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from neuralcoref) (2.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from neuralcoref) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.26.6)\n",
      "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (0.8.2)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (2.0.5)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.32.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from boto3->neuralcoref) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from boto3->neuralcoref) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from boto3->neuralcoref) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from botocore<1.22.0,>=1.21.2->boto3->neuralcoref) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.2->boto3->neuralcoref) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install neuralcoref --no-binary neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T03:55:27.809344Z",
     "start_time": "2021-07-21T03:55:22.864570Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-metric\n",
      "  Downloading rouge_metric-1.0.1-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: rouge-metric\n",
      "Successfully installed rouge-metric-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:50.892791Z",
     "start_time": "2021-07-23T05:50:35.815087Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "from typing import Dict\n",
    "from transformers import (PreTrainedModel, PreTrainedTokenizer,\n",
    "                          BertModel, BertTokenizer,\n",
    "                          GPT2Model, GPT2Tokenizer,\n",
    "                          BartModel, BartTokenizer, \n",
    "                          OpenAIGPTModel, OpenAIGPTTokenizer, \n",
    "                          CTRLModel, CTRLTokenizer, \n",
    "                          TransfoXLModel, TransfoXLTokenizer, \n",
    "                          XLNetModel, XLNetTokenizer,\n",
    "                          XLMModel, XLMTokenizer, \n",
    "                          DistilBertModel, DistilBertTokenizer,\n",
    "                          AlbertModel, AlbertTokenizer,\n",
    "                          AutoModel, AutoTokenizer)\n",
    "\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import neuralcoref\n",
    "import spacy\n",
    "\n",
    "from numpy import ndarray\n",
    "from spacy.lang.vi import Vietnamese\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:50.911122Z",
     "start_time": "2021-07-23T05:50:50.892791Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from rouge_metric import PyRouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:52.304838Z",
     "start_time": "2021-07-23T05:50:50.915111Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup classes & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:52.493997Z",
     "start_time": "2021-07-23T05:50:52.466068Z"
    },
    "code_folding": [
     2,
     6
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "class BertParent(object):\n",
    "    \"\"\"\n",
    "    Base handler for BERT models.\n",
    "    \"\"\"\n",
    "    MODELS = {\n",
    "                'bert-base-multilingual-uncased': (BertModel, BertTokenizer),\n",
    "                'bert-base-uncased': (BertModel, BertTokenizer),\n",
    "                'bert-large-uncased': (BertModel, BertTokenizer),\n",
    "                'gpt2': (GPT2Model, GPT2Tokenizer),\n",
    "                'facebook/bart-large': (BartModel, BartTokenizer),\n",
    "                'openai-gpt': (OpenAIGPTModel, OpenAIGPTTokenizer),\n",
    "                'ctrl': (CTRLModel, CTRLTokenizer),\n",
    "                'transfo-xl-wt103': (TransfoXLModel, TransfoXLTokenizer), \n",
    "                'xlnet-large-cased': (XLNetModel, XLNetTokenizer),\n",
    "                'xlnet-base-cased': (XLNetModel, XLNetTokenizer),\n",
    "                'xlm-mlm-enfr-1024': (XLMModel, XLMTokenizer),\n",
    "                'distilbert-base-uncased': (DistilBertModel, DistilBertTokenizer),\n",
    "                'albert-base-v2': (AlbertModel, AlbertTokenizer),\n",
    "                'albert-large-v2': (AlbertModel, AlbertTokenizer),\n",
    "                'allenai/scibert_scivocab_uncased': (AutoModel, AutoTokenizer),\n",
    "                'vinai/phobert-large': (AutoModel, AutoTokenizer)\n",
    "    }\n",
    "\n",
    "    def __init__(self,\n",
    "                model: str,\n",
    "                custom_model: PreTrainedModel = None,\n",
    "                custom_tokenizer: PreTrainedTokenizer = None):\n",
    "        \"\"\"\n",
    "        :param model: Model is the string path for the bert weights. If given a keyword, the s3 path will be used.\n",
    "        :param custom_model: This is optional if a custom bert model is used.\n",
    "        :param custom_tokenizer: Place to use custom tokenizer.\n",
    "        \"\"\"\n",
    "        base_model, base_tokenizer = self.MODELS.get(model, (None, None))\n",
    "\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        if custom_model:\n",
    "            self.model = custom_model.to(self.device)\n",
    "        else:\n",
    "            self.model = base_model.from_pretrained(model, output_hidden_states=True).to(self.device)\n",
    "\n",
    "        if custom_tokenizer:\n",
    "            self.tokenizer = custom_tokenizer\n",
    "        else:\n",
    "            self.tokenizer = base_tokenizer.from_pretrained(model)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def tokenize_input(self, text: str) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Tokenizes the text input.\n",
    "        :param text: Text to tokenize.\n",
    "        :return: Returns a torch tensor.\n",
    "        \"\"\"\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        return torch.tensor([indexed_tokens]).to(self.device) \n",
    "\n",
    "    def extract_embeddings(self,\n",
    "                        text: str,\n",
    "                        hidden: Union[List[int], int] = -2,\n",
    "                        reduce_option: str = 'mean',\n",
    "                        hidden_concat: bool = False) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Extracts the embeddings for the given text.\n",
    "        :param text: The text to extract embeddings for.\n",
    "        :param hidden: The hidden layer(s) to use for a readout handler.\n",
    "        :param squeeze: If we should squeeze the outputs (required for some layers).\n",
    "        :param reduce_option: How we should reduce the items.\n",
    "        :param hidden_concat: Whether or not to concat multiple hidden layers.\n",
    "        :return: A torch vector.\n",
    "        \"\"\"\n",
    "        tokens_tensor = self.tokenize_input(text)\n",
    "        pooled, hidden_states = self.model(tokens_tensor)[-2:]\n",
    "\n",
    "        # deprecated temporary keyword functions.\n",
    "        \n",
    "        if reduce_option == 'concat_last_4':\n",
    "            last_4 = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "            cat_hidden_states = torch.cat(tuple(last_4), dim=-1)\n",
    "            return torch.mean(cat_hidden_states, dim=1).squeeze()\n",
    "\n",
    "        elif reduce_option == 'reduce_last_4':\n",
    "            last_4 = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "            return torch.cat(tuple(last_4), dim=1).mean(axis=1).squeeze()\n",
    "\n",
    "        elif type(hidden) == int:\n",
    "            hidden_s = hidden_states[hidden]\n",
    "            return self._pooled_handler(hidden_s, reduce_option)\n",
    "\n",
    "        elif hidden_concat:\n",
    "            last_states = [hidden_states[i] for i in hidden]\n",
    "            cat_hidden_states = torch.cat(tuple(last_states), dim=-1)\n",
    "            return torch.mean(cat_hidden_states, dim=1).squeeze()\n",
    "\n",
    "        last_states = [hidden_states[i] for i in hidden]\n",
    "        hidden_s = torch.cat(tuple(last_states), dim=1)\n",
    "\n",
    "        return self._pooled_handler(hidden_s, reduce_option)\n",
    "    \n",
    "    def create_matrix(self,\n",
    "                    content: List[str],\n",
    "                    hidden: Union[List[int], int] = -2,\n",
    "                    reduce_option: str = 'mean',\n",
    "                    hidden_concat: bool = False) -> ndarray:\n",
    "        \"\"\"\n",
    "        Create matrix from the embeddings.\n",
    "        :param content: The list of sentences.\n",
    "        :param hidden: Which hidden layer to use.\n",
    "        :param reduce_option: The reduce option to run.\n",
    "        :param hidden_concat: Whether or not to concat multiple hidden layers.\n",
    "        :return: A numpy array matrix of the given content.\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.asarray([\n",
    "            np.squeeze(self.extract_embeddings(t, hidden=hidden, reduce_option=reduce_option, \n",
    "                                               hidden_concat=hidden_concat).data.cpu().numpy()) for t in content])\n",
    "    \n",
    "    def _pooled_handler(self, hidden: torch.Tensor,\n",
    "                        reduce_option: str) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Handles torch tensor.\n",
    "\n",
    "        :param hidden: The hidden torch tensor to process.\n",
    "        :param reduce_option: The reduce option to use, such as mean, etc.\n",
    "        :return: Returns a torch tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        if reduce_option == 'max':\n",
    "            return hidden.max(dim=1)[0].squeeze()\n",
    "\n",
    "        elif reduce_option == 'median':\n",
    "            return hidden.median(dim=1)[0].squeeze()\n",
    "\n",
    "        return hidden.mean(dim=1).squeeze()\n",
    "\n",
    "    def __call__(self,\n",
    "                content: List[str],\n",
    "                hidden: int = -2,\n",
    "                reduce_option: str = 'mean',\n",
    "                hidden_concat: bool = False) -> ndarray:\n",
    "        \"\"\"\n",
    "        Create matrix from the embeddings.\n",
    "\n",
    "        :param content: The list of sentences.\n",
    "        :param hidden: Which hidden layer to use.\n",
    "        :param reduce_option: The reduce option to run.\n",
    "        :param hidden_concat: Whether or not to concat multiple hidden layers.\n",
    "        :return: A numpy array matrix of the given content.\n",
    "        \"\"\"\n",
    "        return self.create_matrix(content, hidden, reduce_option, hidden_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:52.514938Z",
     "start_time": "2021-07-23T05:50:52.495989Z"
    },
    "code_folding": [
     0,
     16,
     38,
     52,
     66
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SentenceHandler(object):\n",
    "    def __init__(self, language=Vietnamese):\n",
    "        \"\"\"\n",
    "        Base Sentence Handler with Spacy support.\n",
    "        :param language: Determines the language to use with spacy.\n",
    "        \"\"\"\n",
    "        self.nlp = language()\n",
    "        try:\n",
    "            # Supports spacy 2.0\n",
    "            self.nlp.add_pipe(self.nlp.create_pipe('sentencizer'))\n",
    "            self.is_spacy_3 = False\n",
    "        except Exception:\n",
    "            # Supports spacy 3.0\n",
    "            self.nlp.add_pipe(\"sentencizer\")\n",
    "            self.is_spacy_3 = True\n",
    "\n",
    "    def sentence_processor(self, doc,\n",
    "                           min_length: int = 40,\n",
    "                           max_length: int = 600) -> List[str]:\n",
    "        \"\"\"\n",
    "        Processes a given spacy document and turns them into sentences.\n",
    "        :param doc: The document to use from spacy.\n",
    "        :param min_length: The minimum length a sentence should be to be considered.\n",
    "        :param max_length: The maximum length a sentence should be to be considered.\n",
    "        :return: Sentences.\n",
    "        \"\"\"\n",
    "        to_return = []\n",
    "\n",
    "        for c in doc.sents:\n",
    "            if max_length > len(c.text.strip()) > min_length:\n",
    "\n",
    "                if self.is_spacy_3:\n",
    "                    to_return.append(c.text.strip())\n",
    "                else:\n",
    "                    to_return.append(c.string.strip())\n",
    "\n",
    "        return to_return\n",
    "\n",
    "    def process(self, body: str,\n",
    "                min_length: int = 40,\n",
    "                max_length: int = 600) -> List[str]:\n",
    "        \"\"\"\n",
    "        Processes the content sentences.\n",
    "\n",
    "        :param body: The raw string body to process\n",
    "        :param min_length: Minimum length that the sentences must be\n",
    "        :param max_length: Max length that the sentences mus fall under\n",
    "        :return: Returns a list of sentences.\n",
    "        \"\"\"\n",
    "        doc = self.nlp(body)\n",
    "        return self.sentence_processor(doc, min_length, max_length)\n",
    "\n",
    "    def __call__(self, body: str,\n",
    "                 min_length: int = 40,\n",
    "                 max_length: int = 600) -> List[str]:\n",
    "        \"\"\"\n",
    "        Processes the content sentences.\n",
    "\n",
    "        :param body: The raw string body to process\n",
    "        :param min_length: Minimum length that the sentences must be\n",
    "        :param max_length: Max length that the sentences mus fall under\n",
    "        :return: Returns a list of sentences.\n",
    "        \"\"\"\n",
    "        return self.process(body, min_length, max_length)\n",
    "# removed previous import and related functionality since it's just a blank language model,\n",
    "# while neuralcoref requires passing pretrained language model via spacy.load() or spacy.lang.vi\n",
    "class CoreferenceHandler(SentenceHandler):\n",
    "    def __init__(self, spacy_model = Vietnamese,\n",
    "                 greedyness: float = 0.45):\n",
    "        \"\"\"\n",
    "        Corefence handler. Only works with spacy < 3.0.\n",
    "        :param spacy_model: The spacy model to use as default.\n",
    "        :param greedyness: The greedyness factor.\n",
    "        \"\"\"\n",
    "        self.nlp = spacy_model()\n",
    "            \n",
    "        self.nlp.add_pipe(self.nlp.create_pipe('sentencizer'))\n",
    "        neuralcoref.add_to_pipe(self.nlp, greedyness=greedyness)\n",
    "\n",
    "    def process(self, body: str, min_length: int = 40, max_length: int = 600):\n",
    "        \"\"\"\n",
    "        Processes the content sentences.\n",
    "        :param body: The raw string body to process\n",
    "        :param min_length: Minimum length that the sentences must be\n",
    "        :param max_length: Max length that the sentences mus fall under\n",
    "        :return: Returns a list of sentences.\n",
    "        \"\"\"\n",
    "        doc = self.nlp(body)._.coref_resolved\n",
    "        doc = self.nlp(doc)\n",
    "        return [c.string.strip()\n",
    "                for c in doc.sents\n",
    "                if max_length > len(c.string.strip()) > min_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:52.538874Z",
     "start_time": "2021-07-23T05:50:52.516933Z"
    },
    "code_folding": [
     0,
     4,
     22,
     32,
     42,
     65,
     87,
     99,
     127
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ClusterFeatures(object):\n",
    "    \"\"\"\n",
    "    Basic handling of clustering features.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                features: ndarray,\n",
    "                algorithm: str = 'kmeans',\n",
    "                pca_k: int = None,\n",
    "                random_state: int = 12345):\n",
    "        \"\"\"\n",
    "        :param features: the embedding matrix created by bert parent.\n",
    "        :param algorithm: Which clustering algorithm to use.\n",
    "        :param pca_k: If you want the features to be ran through pca, this is the components number.\n",
    "        :param random_state: Random state.\n",
    "        \"\"\"\n",
    "        if pca_k: self.features = PCA(n_components=pca_k).fit_transform(features)\n",
    "        else: self.features = features\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "        self.pca_k = pca_k\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def __get_model(self, k: int):\n",
    "        \"\"\"\n",
    "        Retrieve clustering model.\n",
    "        :param k: amount of clusters.\n",
    "        :return: Clustering model.\n",
    "        \"\"\"\n",
    "        if self.algorithm == 'gmm':\n",
    "            return GaussianMixture(n_components=k, random_state=self.random_state)\n",
    "        return KMeans(n_clusters=k, random_state=self.random_state)\n",
    "\n",
    "    def __get_centroids(self, model):\n",
    "        \"\"\"\n",
    "        Retrieve centroids of model.\n",
    "        :param model: Clustering model.\n",
    "        :return: Centroids.\n",
    "        \"\"\"\n",
    "        if self.algorithm == 'gmm':\n",
    "            return model.means_\n",
    "        return model.cluster_centers_\n",
    "\n",
    "    def __find_closest_args(self, centroids: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Find the closest arguments to centroid.\n",
    "        :param centroids: Centroids to find closest.\n",
    "        :return: Closest arguments.\n",
    "        \"\"\"\n",
    "        centroid_min = 1e10\n",
    "        cur_arg = -1\n",
    "        args = {}\n",
    "        used_idx = []\n",
    "\n",
    "        for j, centroid in enumerate(centroids):\n",
    "            for i, feature in enumerate(self.features):\n",
    "                value = np.linalg.norm(feature - centroid)\n",
    "                if value < centroid_min and i not in used_idx:\n",
    "                    cur_arg = i\n",
    "                    centroid_min = value\n",
    "            used_idx.append(cur_arg)\n",
    "            args[j] = cur_arg\n",
    "            centroid_min = 1e10\n",
    "            cur_arg = -1\n",
    "        return args\n",
    "\n",
    "    def cluster(self, ratio: float = 0.1, num_sentences: int = None) -> List[int]:\n",
    "        \"\"\"\n",
    "        Clusters sentences based on the ratio.\n",
    "        :param ratio: Ratio to use for clustering.\n",
    "        :param num_sentences: Number of sentences. Overrides ratio.\n",
    "        :return: Sentences index that qualify for summary.\n",
    "        \"\"\"\n",
    "        if num_sentences is not None:\n",
    "            if num_sentences == 0: return []\n",
    "            k = min(num_sentences, len(self.features))\n",
    "        else:\n",
    "            k = max(int(len(self.features) * ratio), 1)\n",
    "        \n",
    "        #k = max(int(len(self.features) * ratio), 1)\n",
    "        model = self.__get_model(k).fit(self.features)\n",
    "\n",
    "        centroids = self.__get_centroids(model)\n",
    "        cluster_args = self.__find_closest_args(centroids)\n",
    "\n",
    "        sorted_values = sorted(cluster_args.values())\n",
    "        return sorted_values\n",
    "\n",
    "    def calculate_elbow(self, k_max: int) -> List[float]:\n",
    "        \"\"\"\n",
    "        Calculates elbow up to the provided k_max.\n",
    "        :param k_max: K_max to calculate elbow for.\n",
    "        :return: The inertias up to k_max.\n",
    "        \"\"\"\n",
    "        inertias = []\n",
    "        for k in range(1, min(k_max, len(self.features))):\n",
    "            model = self.__get_model(k).fit(self.features)\n",
    "            inertias.append(model.inertia_)\n",
    "        return inertias\n",
    "\n",
    "    def calculate_optimal_cluster(self, k_max: int):\n",
    "        \"\"\"\n",
    "        Calculates the optimal cluster based on Elbow.\n",
    "        :param k_max: The max k to search elbow for.\n",
    "        :return: The optimal cluster size.\n",
    "        \"\"\"\n",
    "        delta_1 = []\n",
    "        delta_2 = []\n",
    "\n",
    "        max_strength = 0\n",
    "        k = 1\n",
    "\n",
    "        inertias = self.calculate_elbow(k_max)\n",
    "\n",
    "        for i in range(len(inertias)):\n",
    "            delta_1.append(inertias[i] - inertias[i-1] if i > 0 else 0.0)\n",
    "            delta_2.append(delta_1[i] - delta_1[i-1] if i > 1 else 0.0)\n",
    "\n",
    "        for j in range(len(inertias)):\n",
    "            strength = 0 if j <= 1 or j == len(\n",
    "                inertias) - 1 else delta_2[j+1] - delta_1[j+1]\n",
    "\n",
    "            if strength > max_strength:\n",
    "                max_strength = strength\n",
    "                k = j + 1\n",
    "\n",
    "        return k\n",
    "\n",
    "    def __call__(self, ratio: float = 0.1, num_sentences: int = None) -> List[int]:\n",
    "        \"\"\"\n",
    "        Clusters sentences based on the ratio.\n",
    "        :param ratio: Ratio to use for clustering.\n",
    "        :param num_sentences: Number of sentences. Overrides ratio.\n",
    "        :return: Sentences index that qualify for summary.\n",
    "        \"\"\"\n",
    "        return self.cluster(ratio, num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:52.895127Z",
     "start_time": "2021-07-23T05:50:52.541866Z"
    },
    "code_folding": [
     0,
     35,
     72,
     91,
     109,
     137,
     165,
     233,
     259,
     283,
     287
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ModelProcessor(object):\n",
    "    aggregate_map = {'mean': np.mean,\n",
    "                    'min': np.min,\n",
    "                    'median': np.median,\n",
    "                    'max': np.max}\n",
    "\n",
    "    def __init__(self,\n",
    "                model: str = 'bert-base-multilingual-uncased',\n",
    "                custom_model: PreTrainedModel = None,\n",
    "                custom_tokenizer: PreTrainedTokenizer = None,\n",
    "                hidden: Union[List[int], int] = -2,\n",
    "                reduce_option: str = 'mean',\n",
    "                sentence_handler: SentenceHandler = SentenceHandler(),\n",
    "                random_state: int = 12345,\n",
    "                hidden_concat: bool = False):\n",
    "        \"\"\"\n",
    "        This is the parent Bert Summarizer model. New methods should implement this class.\n",
    "        :param model: This parameter is associated with the inherit string parameters from the transformers library.\n",
    "        :param custom_model: If you have a pre-trained model, you can add the model class here.\n",
    "        :param custom_tokenizer: If you have a custom tokenizer, you can add the tokenizer here.\n",
    "        :param hidden: This signifies which layer(s) of the BERT model you would like to use as embeddings.\n",
    "        :param reduce_option: Given the output of the bert model, this param determines how you want to reduce results.\n",
    "        :param sentence_handler: The handler to process sentences. If want to use coreference, instantiate and pass.\n",
    "        CoreferenceHandler instance\n",
    "        :param random_state: The random state to reproduce summarizations.\n",
    "        :param hidden_concat: Whether or not to concat multiple hidden layers.\n",
    "        \"\"\"\n",
    "        np.random.seed(random_state)\n",
    "        self.model = BertParent(model, custom_model, custom_tokenizer)\n",
    "        self.hidden = hidden\n",
    "        self.reduce_option = reduce_option\n",
    "        self.sentence_handler = sentence_handler\n",
    "        self.random_state = random_state\n",
    "        self.hidden_concat = hidden_concat\n",
    "\n",
    "    def cluster_runner(self,\n",
    "        content: List[str],\n",
    "        ratio: float = 0.2,\n",
    "        algorithm: str = 'kmeans',\n",
    "        use_first: bool = True,\n",
    "        num_sentences: int = None) -> Tuple[List[str], np.ndarray]:\n",
    "        \"\"\"\n",
    "        Runs the cluster algorithm based on the hidden state. Returns both the embeddings and sentences.\n",
    "\n",
    "        :param content: Content list of sentences.\n",
    "        :param ratio: The ratio to use for clustering.\n",
    "        :param algorithm: Type of algorithm to use for clustering.\n",
    "        :param use_first: Return the first sentence in the output (helpful for news stories, etc).\n",
    "        :param num_sentences: Number of sentences to use for summarization.\n",
    "        :return: A tuple of summarized sentences and embeddings\n",
    "        \"\"\"\n",
    "        \n",
    "        if num_sentences is not None:\n",
    "            num_sentences = num_sentences if use_first else num_sentences\n",
    "\n",
    "        hidden = self.model(\n",
    "            content, self.hidden, self.reduce_option, hidden_concat=self.hidden_concat)\n",
    "        hidden_args = ClusterFeatures(\n",
    "            hidden, algorithm, random_state=self.random_state).cluster(ratio, num_sentences)\n",
    "        \n",
    "        if use_first:\n",
    "            if not hidden_args:\n",
    "                hidden_args.append(0)\n",
    "\n",
    "            elif hidden_args[0] != 0:\n",
    "                hidden_args.insert(0, 0)\n",
    "\n",
    "        sentences = [content[j] for j in hidden_args]\n",
    "        embeddings = np.asarray([hidden[j] for j in hidden_args])\n",
    "\n",
    "        return sentences, embeddings\n",
    "\n",
    "    def __run_clusters(self,\n",
    "                    content: List[str],\n",
    "                    ratio: float = 0.2,\n",
    "                    algorithm: str = 'kmeans',\n",
    "                    use_first: bool = True,\n",
    "                    num_sentences: int = None) -> List[str]:\n",
    "        \"\"\"\n",
    "        Runs clusters and returns sentences.\n",
    "        :param content: The content of sentences.\n",
    "        :param ratio: Ratio to use for for clustering.\n",
    "        :param algorithm: Algorithm selection for clustering.\n",
    "        :param use_first: Whether to use first sentence\n",
    "        :param num_sentences: Number of sentences. Overrides ratio.\n",
    "        :return: summarized sentences\n",
    "        \"\"\"\n",
    "        sentences, _ = self.cluster_runner(\n",
    "            content, ratio, algorithm, use_first, num_sentences)\n",
    "        return sentences\n",
    "\n",
    "    def __retrieve_summarized_embeddings(self,\n",
    "                                        content: List[str],\n",
    "                                        ratio: float = 0.2,\n",
    "                                        algorithm: str = 'kmeans',\n",
    "                                        use_first: bool = True,\n",
    "                                        num_sentences: int = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Retrieves embeddings of the summarized sentences.\n",
    "        :param content: The content of sentences.\n",
    "        :param ratio: Ratio to use for for clustering.\n",
    "        :param algorithm: Algorithm selection for clustering.\n",
    "        :param use_first: Whether to use first sentence\n",
    "        :return: Summarized embeddings\n",
    "        \"\"\"\n",
    "        _, embeddings = self.cluster_runner(\n",
    "            content, ratio, algorithm, use_first, num_sentences)\n",
    "        return embeddings\n",
    "\n",
    "    def calculate_elbow(self,\n",
    "                        body: str,\n",
    "                        algorithm: str = 'kmeans',\n",
    "                        min_length: int = 40,\n",
    "                        max_length: int = 600,\n",
    "                        k_max: int = None) -> List[float]:\n",
    "        \"\"\"\n",
    "        Calculates elbow across the clusters.\n",
    "\n",
    "        :param body: The input body to summarize.\n",
    "        :param algorithm: The algorithm to use for clustering.\n",
    "        :param min_length: The min length to use.\n",
    "        :param max_length: The max length to use.\n",
    "        :param k_max: The maximum number of clusters to search.\n",
    "        :return: List of elbow inertia values.\n",
    "        \"\"\"\n",
    "        sentences = self.sentence_handler(body, min_length, max_length)\n",
    "\n",
    "        if k_max is None:\n",
    "            k_max = len(sentences) - 1\n",
    "\n",
    "        hidden = self.model(sentences, self.hidden,\n",
    "                            self.reduce_option, hidden_concat=self.hidden_concat)\n",
    "        elbow = ClusterFeatures(\n",
    "            hidden, algorithm, random_state=self.random_state).calculate_elbow(k_max)\n",
    "\n",
    "        return elbow\n",
    "\n",
    "    def calculate_optimal_k(self,\n",
    "                            body: str,\n",
    "                            algorithm: str = 'kmeans',\n",
    "                            min_length: int = 40,\n",
    "                            max_length: int = 600,\n",
    "                            k_max: int = None):\n",
    "        \"\"\"\n",
    "        Calculates the optimal Elbow K.\n",
    "\n",
    "        :param body: The input body to summarize.\n",
    "        :param algorithm: The algorithm to use for clustering.\n",
    "        :param min_length: The min length to use.\n",
    "        :param max_length: The max length to use.\n",
    "        :param k_max: The maximum number of clusters to search.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        sentences = self.sentence_handler(body, min_length, max_length)\n",
    "\n",
    "        if k_max is None:\n",
    "            k_max = len(sentences) - 1\n",
    "\n",
    "        hidden = self.model(sentences, self.hidden,\n",
    "                            self.reduce_option, hidden_concat=self.hidden_concat)\n",
    "        optimal_k = ClusterFeatures(\n",
    "            hidden, algorithm, random_state=self.random_state).calculate_optimal_cluster(k_max)\n",
    "\n",
    "        return optimal_k\n",
    "\n",
    "    def run_embeddings(self,\n",
    "                    body: str,\n",
    "                    ratio: float = 0.2,\n",
    "                    min_length: int = 40,\n",
    "                    max_length: int = 600,\n",
    "                    use_first: bool = True,\n",
    "                    algorithm: str = 'kmeans',\n",
    "                    num_sentences: int = None,\n",
    "                    aggregate: str = None) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Preprocesses the sentences, runs the clusters to find the centroids, then combines the embeddings.\n",
    "        :param body: The raw string body to process\n",
    "        :param ratio: Ratio of sentences to use\n",
    "        :param min_length: Minimum length of sentence candidates to utilize for the summary.\n",
    "        :param max_length: Maximum length of sentence candidates to utilize for the summary\n",
    "        :param use_first: Whether or not to use the first sentence\n",
    "        :param algorithm: Which clustering algorithm to use. (kmeans, gmm)\n",
    "        :param num_sentences: Number of sentences to use. Overrides ratio.\n",
    "        :param aggregate: One of mean, median, max, min. Applied on zero axis\n",
    "        :return: A summary embedding\n",
    "        \"\"\"\n",
    "        sentences = self.sentence_handler(body, min_length, max_length)\n",
    "\n",
    "        if sentences:\n",
    "            embeddings = self.__retrieve_summarized_embeddings(\n",
    "                sentences, ratio, algorithm, use_first, num_sentences)\n",
    "\n",
    "            if aggregate is not None:\n",
    "                assert aggregate in [\n",
    "                    'mean', 'median', 'max', 'min'], \"aggregate must be mean, min, max, or median\"\n",
    "                embeddings = self.aggregate_map[aggregate](embeddings, axis=0)\n",
    "\n",
    "            return embeddings\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def run(self,\n",
    "            body: str,\n",
    "            ratio: float = 0.2,\n",
    "            min_length: int = 40,\n",
    "            max_length: int = 600,\n",
    "            use_first: bool = True,\n",
    "            algorithm: str = 'kmeans',\n",
    "            num_sentences: int = None,\n",
    "            return_as_list: bool = False) -> Union[List, str]:\n",
    "        \"\"\"\n",
    "        Preprocesses the sentences, runs the clusters to find the centroids, then combines the sentences.\n",
    "        :param body: The raw string body to process\n",
    "        :param ratio: Ratio of sentences to use\n",
    "        :param min_length: Minimum length of sentence candidates to utilize for the summary.\n",
    "        :param max_length: Maximum length of sentence candidates to utilize for the summary\n",
    "        :param use_first: Whether or not to use the first sentence\n",
    "        :param algorithm: Which clustering algorithm to use. (kmeans, gmm)\n",
    "        :param num_sentences: Number of sentences to use (overrides ratio).\n",
    "        :param return_as_list: Whether or not to return sentences as list.\n",
    "        :return: A summary sentence\n",
    "        \"\"\"\n",
    "        sentences = self.sentence_handler(body, min_length, max_length)\n",
    "\n",
    "        if sentences:\n",
    "            sentences = self.__run_clusters(sentences, ratio, algorithm, use_first, num_sentences)\n",
    "            \n",
    "        #Vietnamese spaCy language package also have _ characters between compound words, so we have to replace it\n",
    "        if return_as_list:\n",
    "            return sentences.replace('_', ' ')\n",
    "        else:\n",
    "            return ' '.join(sentences).replace('_',' ')\n",
    "\n",
    "    def __call__(self,\n",
    "                body: str,\n",
    "                ratio: float = 0.2,\n",
    "                min_length: int = 40,\n",
    "                max_length: int = 600,\n",
    "                use_first: bool = True,\n",
    "                algorithm: str = 'gmm', #kmeans\n",
    "                num_sentences: int = None,\n",
    "                return_as_list: bool = False) -> str:\n",
    "        \"\"\"\n",
    "        (utility that wraps around the run function)\n",
    "        Preprocesses the sentences, runs the clusters to find the centroids, then combines the sentences.\n",
    "        :param body: The raw string body to process.\n",
    "        :param ratio: Ratio of sentences to use.\n",
    "        :param min_length: Minimum length of sentence candidates to utilize for the summary.\n",
    "        :param max_length: Maximum length of sentence candidates to utilize for the summary.\n",
    "        :param use_first: Whether or not to use the first sentence.\n",
    "        :param algorithm: Which clustering algorithm to use. (kmeans, gmm)\n",
    "        :param Number of sentences to use (overrides ratio).\n",
    "        :param return_as_list: Whether or not to return sentences as list.\n",
    "        :return: A summary sentence.\n",
    "        \"\"\"\n",
    "        return self.run(\n",
    "            body, ratio, min_length, max_length, algorithm=algorithm, use_first=use_first, num_sentences=num_sentences,\n",
    "            return_as_list=return_as_list)\n",
    "\n",
    "class Summarizer(ModelProcessor):\n",
    "    def __init__(self,\n",
    "        model: str = 'bert-base-multilingual-uncased',\n",
    "        custom_model: PreTrainedModel = None,\n",
    "        custom_tokenizer: PreTrainedTokenizer = None,\n",
    "        hidden: Union[List[int], int] = -2,\n",
    "        reduce_option: str = 'mean',\n",
    "        sentence_handler: SentenceHandler = SentenceHandler(),\n",
    "        random_state: int = 12345,\n",
    "        hidden_concat: bool = False):\n",
    "        \"\"\"\n",
    "        This is the main Bert Summarizer class.\n",
    "        :param model: This parameter is associated with the inherit string parameters from the transformers library.\n",
    "        :param custom_model: If you have a pre-trained model, you can add the model class here.\n",
    "        :param custom_tokenizer: If you have a custom tokenizer, you can add the tokenizer here.\n",
    "        :param hidden: This signifies which layer of the BERT model you would like to use as embeddings.\n",
    "        :param reduce_option: Given the output of the bert model, this param determines how you want to reduce results.\n",
    "        :param random_state: The random state to reproduce summarizations.\n",
    "        :param hidden_concat: Whether or not to concat multiple hidden layers.\n",
    "        \"\"\"\n",
    "        super(Summarizer, self).__init__(\n",
    "            model, custom_model, custom_tokenizer, hidden, reduce_option, sentence_handler, random_state, hidden_concat\n",
    "        )\n",
    "\n",
    "class TransformerSummarizer(ModelProcessor):\n",
    "    \"\"\"\n",
    "    Newer style that has keywords for models and tokenizers, but allows the user to change the type.\n",
    "    \"\"\"\n",
    "    MODEL_DICT = {\n",
    "                    'Bert': (BertModel, BertTokenizer),\n",
    "                    'GPT2': (GPT2Model, GPT2Tokenizer),\n",
    "                    'OpenAIGPT': (OpenAIGPTModel, OpenAIGPTTokenizer),\n",
    "                    'CTRL': (CTRLModel, CTRLTokenizer),\n",
    "                    'TransfoXL': (TransfoXLModel, TransfoXLTokenizer),\n",
    "                    'XLNet': (XLNetModel, XLNetTokenizer),\n",
    "                    'XLM': (XLMModel, XLMTokenizer),\n",
    "                    'DistilBert': (DistilBertModel, DistilBertTokenizer),\n",
    "                    'ALBERT': (AlbertModel, AlbertTokenizer),\n",
    "                    'phoBERT': (AutoModel, AutoTokenizer),\n",
    "    }\n",
    "    def __init__(self,\n",
    "                transformer_type: str = 'Bert',\n",
    "                transformer_model_key: str = 'bert-base-multilingual-uncased',\n",
    "                transformer_tokenizer_key: str = None,\n",
    "                hidden: Union[List[int], int] = -2,\n",
    "                reduce_option: str = 'mean',\n",
    "                sentence_handler: SentenceHandler = SentenceHandler(),\n",
    "                random_state: int = 12345,\n",
    "                hidden_concat: bool = False):\n",
    "        \"\"\"\n",
    "        :param transformer_type: The Transformer type, such as Bert, GPT2, DistilBert, etc.\n",
    "        :param transformer_model_key: The transformer model key. This is the directory for the model.\n",
    "        :param transformer_tokenizer_key: The transformer tokenizer key. This is the tokenizer directory.\n",
    "        :param hidden: The hidden output layers to use for the summarization.\n",
    "        :param reduce_option: The reduce option, such as mean, max, min, median, etc.\n",
    "        :param sentence_handler: The sentence handler class to process the raw text.\n",
    "        :param random_state: The random state to use.\n",
    "        :param hidden_concat: Deprecated hidden concat option.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.MODEL_DICT['Roberta'] = (RobertaModel, RobertaTokenizer)\n",
    "            self.MODEL_DICT['Albert'] = (AlbertModel, AlbertTokenizer)\n",
    "            self.MODEL_DICT['Camembert'] = (CamembertModel, CamembertTokenizer)\n",
    "            self.MODEL_DICT['Bart'] = (BartModel, BartTokenizer)\n",
    "            self.MODEL_DICT['Longformer'] = (LongformerModel, LongformerTokenizer)\n",
    "        except Exception:\n",
    "            pass  # older transformer version\n",
    "\n",
    "        model_clz, tokenizer_clz = self.MODEL_DICT[transformer_type]\n",
    "        model = model_clz.from_pretrained(\n",
    "            transformer_model_key, output_hidden_states=True)\n",
    "\n",
    "        tokenizer = tokenizer_clz.from_pretrained(\n",
    "            transformer_tokenizer_key if transformer_tokenizer_key is not None else transformer_model_key\n",
    "        )\n",
    "\n",
    "        super().__init__(\n",
    "            None, model, tokenizer, hidden, reduce_option, sentence_handler, random_state, hidden_concat\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:52.902934Z",
     "start_time": "2021-07-23T05:50:52.897932Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rouge_dist(hypotheses, references):\n",
    "    rouge = PyRouge(rouge_n=(1, 2), rouge_l=True, rouge_su=True, skip_gap=4)\n",
    "    scores = rouge.evaluate(hypotheses, references)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:52.916908Z",
     "start_time": "2021-07-23T05:50:52.905900Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def loadtxt(path, ref=False):\n",
    "    bodyinput=[]\n",
    "    # Change the directory\n",
    "    os.chdir(path)\n",
    "    # Read text File  \n",
    "    def read_text_file(file_path):\n",
    "        with open(file_path, 'r', encoding = 'utf-8') as f:\n",
    "            ftext = f.read()\n",
    "            ftext = ftext.replace('\\ufeff ','').replace('\\ufeff','').replace('\\n','')\n",
    "            return ftext\n",
    "        \n",
    "    # iterate through all file\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = f\"{path}\\{file}\"\n",
    "            if ref:\n",
    "                bodyinput.append([read_text_file(file_path)])\n",
    "            else: \n",
    "                bodyinput.append(read_text_file(file_path))\n",
    "    return bodyinput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:53.250984Z",
     "start_time": "2021-07-23T05:50:53.245005Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "                'bert-base-multilingual-uncased': (BertModel, BertTokenizer),\n",
    "                'bert-large-uncased': (BertModel, BertTokenizer),\n",
    "                'gpt2': (GPT2Model, GPT2Tokenizer),\n",
    "                'facebook/bart-large': (BartModel, BartTokenizer),\n",
    "                'openai-gpt': (OpenAIGPTModel, OpenAIGPTTokenizer),\n",
    "                'ctrl': (CTRLModel, CTRLTokenizer),\n",
    "                'transfo-xl-wt103': (TransfoXLModel, TransfoXLTokenizer), \n",
    "                'xlnet-large-cased': (XLNetModel, XLNetTokenizer),\n",
    "                'xlm-mlm-enfr-1024': (XLMModel, XLMTokenizer),\n",
    "                'distilbert-base-uncased': (DistilBertModel, DistilBertTokenizer),\n",
    "                'albert-large-v2': (AlbertModel, AlbertTokenizer),\n",
    "                'allenai/scibert_scivocab_uncased': (AutoModel, AutoTokenizer),\n",
    "                'vinai/phobert-large': (AutoModel, AutoTokenizer)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T05:50:53.302846Z",
     "start_time": "2021-07-23T05:50:53.297858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "category = ['boKHCN', 'Chinh Tri', 'khoahoc_giaoduc', 'kinhte', 'Van Hoa', 'Xa Hoi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:11:29.299015Z",
     "start_time": "2021-07-21T14:11:28.883358Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = category[0]\n",
    "pathbody = 'E:/TextSummarization/donvanban/Plaintext/' + idx \n",
    "pathref = 'E:/TextSummarization/donvanban/Summary_manual/' + idx \n",
    "rootbody = loadtxt(pathbody)\n",
    "refbody = loadtxt(pathref, ref=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T15:07:04.685217Z",
     "start_time": "2021-07-21T14:11:33.662318Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_transfo_xl.py:146: FutureWarning: The config parameter `tie_weight` is deprecated. Please use `tie_word_embeddings` instead.\n",
      "  FutureWarning,\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "res = {'Rouge1_p':[], 'Rouge2_p':[], 'RougeL_p':[], 'RougeSU4_p': [],\n",
    "        'Rouge1_r':[], 'Rouge2_r':[], 'RougeL_r':[], 'RougeSU4_r': [],\n",
    "        'Rouge1_f':[], 'Rouge2_f':[], 'RougeL_f':[], 'RougeSU4_f': [],\n",
    "      }\n",
    "\n",
    "for idx in model_dict.keys():    \n",
    "    model = Summarizer(model = idx, sentence_handler=CoreferenceHandler())\n",
    "    all_result = []\n",
    "    for jdx in range(len(rootbody)):\n",
    "        result = model(rootbody[jdx], ratio=2*len(refbody[jdx])/len(rootbody[jdx]))\n",
    "        all_result.append(result)\n",
    "    r_rouge = rouge_dist(all_result, refbody)\n",
    "    for ind in ['p', 'r', 'f']:\n",
    "        res['Rouge1_'+ind].append(r_rouge['rouge-1'][ind])\n",
    "        res['Rouge2_'+ind].append(r_rouge['rouge-2'][ind])\n",
    "        res['RougeL_'+ind].append(r_rouge['rouge-l'][ind])\n",
    "        res['RougeSU4_'+ind].append(r_rouge['rouge-su4'][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T15:07:21.238799Z",
     "start_time": "2021-07-21T15:07:21.176706Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rouge1_p</th>\n",
       "      <th>Rouge2_p</th>\n",
       "      <th>RougeL_p</th>\n",
       "      <th>RougeSU4_p</th>\n",
       "      <th>Rouge1_r</th>\n",
       "      <th>Rouge2_r</th>\n",
       "      <th>RougeL_r</th>\n",
       "      <th>RougeSU4_r</th>\n",
       "      <th>Rouge1_f</th>\n",
       "      <th>Rouge2_f</th>\n",
       "      <th>RougeL_f</th>\n",
       "      <th>RougeSU4_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.589949</td>\n",
       "      <td>0.468815</td>\n",
       "      <td>0.471425</td>\n",
       "      <td>0.440070</td>\n",
       "      <td>0.531650</td>\n",
       "      <td>0.419202</td>\n",
       "      <td>0.422021</td>\n",
       "      <td>0.392686</td>\n",
       "      <td>0.559284</td>\n",
       "      <td>0.442622</td>\n",
       "      <td>0.445357</td>\n",
       "      <td>0.415030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-large-uncased</th>\n",
       "      <td>0.577423</td>\n",
       "      <td>0.442054</td>\n",
       "      <td>0.440485</td>\n",
       "      <td>0.413317</td>\n",
       "      <td>0.443022</td>\n",
       "      <td>0.337761</td>\n",
       "      <td>0.336407</td>\n",
       "      <td>0.315294</td>\n",
       "      <td>0.501372</td>\n",
       "      <td>0.382934</td>\n",
       "      <td>0.381475</td>\n",
       "      <td>0.357712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.592837</td>\n",
       "      <td>0.456343</td>\n",
       "      <td>0.459239</td>\n",
       "      <td>0.423710</td>\n",
       "      <td>0.477464</td>\n",
       "      <td>0.366082</td>\n",
       "      <td>0.367362</td>\n",
       "      <td>0.339460</td>\n",
       "      <td>0.528932</td>\n",
       "      <td>0.406259</td>\n",
       "      <td>0.408194</td>\n",
       "      <td>0.376934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large</th>\n",
       "      <td>0.559149</td>\n",
       "      <td>0.418020</td>\n",
       "      <td>0.430839</td>\n",
       "      <td>0.388407</td>\n",
       "      <td>0.472508</td>\n",
       "      <td>0.358028</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.333033</td>\n",
       "      <td>0.512190</td>\n",
       "      <td>0.385705</td>\n",
       "      <td>0.395781</td>\n",
       "      <td>0.358595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt</th>\n",
       "      <td>0.572291</td>\n",
       "      <td>0.433563</td>\n",
       "      <td>0.442683</td>\n",
       "      <td>0.404568</td>\n",
       "      <td>0.466779</td>\n",
       "      <td>0.355695</td>\n",
       "      <td>0.361708</td>\n",
       "      <td>0.331607</td>\n",
       "      <td>0.514178</td>\n",
       "      <td>0.390787</td>\n",
       "      <td>0.398120</td>\n",
       "      <td>0.364472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctrl</th>\n",
       "      <td>0.572195</td>\n",
       "      <td>0.439382</td>\n",
       "      <td>0.430547</td>\n",
       "      <td>0.413148</td>\n",
       "      <td>0.516807</td>\n",
       "      <td>0.388970</td>\n",
       "      <td>0.382233</td>\n",
       "      <td>0.363626</td>\n",
       "      <td>0.543093</td>\n",
       "      <td>0.412642</td>\n",
       "      <td>0.404954</td>\n",
       "      <td>0.386809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfo-xl-wt103</th>\n",
       "      <td>0.599472</td>\n",
       "      <td>0.454298</td>\n",
       "      <td>0.446087</td>\n",
       "      <td>0.423647</td>\n",
       "      <td>0.411946</td>\n",
       "      <td>0.304241</td>\n",
       "      <td>0.302832</td>\n",
       "      <td>0.282794</td>\n",
       "      <td>0.488324</td>\n",
       "      <td>0.364427</td>\n",
       "      <td>0.360758</td>\n",
       "      <td>0.339179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlnet-large-cased</th>\n",
       "      <td>0.585887</td>\n",
       "      <td>0.463378</td>\n",
       "      <td>0.466526</td>\n",
       "      <td>0.435221</td>\n",
       "      <td>0.532594</td>\n",
       "      <td>0.418054</td>\n",
       "      <td>0.419548</td>\n",
       "      <td>0.392126</td>\n",
       "      <td>0.557971</td>\n",
       "      <td>0.439551</td>\n",
       "      <td>0.441791</td>\n",
       "      <td>0.412551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-mlm-enfr-1024</th>\n",
       "      <td>0.573055</td>\n",
       "      <td>0.437195</td>\n",
       "      <td>0.430924</td>\n",
       "      <td>0.407219</td>\n",
       "      <td>0.425831</td>\n",
       "      <td>0.316865</td>\n",
       "      <td>0.318507</td>\n",
       "      <td>0.294447</td>\n",
       "      <td>0.488594</td>\n",
       "      <td>0.367429</td>\n",
       "      <td>0.366284</td>\n",
       "      <td>0.341771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert-base-uncased</th>\n",
       "      <td>0.562064</td>\n",
       "      <td>0.423952</td>\n",
       "      <td>0.431258</td>\n",
       "      <td>0.395780</td>\n",
       "      <td>0.495183</td>\n",
       "      <td>0.379124</td>\n",
       "      <td>0.383464</td>\n",
       "      <td>0.354335</td>\n",
       "      <td>0.526508</td>\n",
       "      <td>0.400287</td>\n",
       "      <td>0.405959</td>\n",
       "      <td>0.373912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albert-large-v2</th>\n",
       "      <td>0.576495</td>\n",
       "      <td>0.444851</td>\n",
       "      <td>0.446179</td>\n",
       "      <td>0.418132</td>\n",
       "      <td>0.461067</td>\n",
       "      <td>0.356349</td>\n",
       "      <td>0.357276</td>\n",
       "      <td>0.334547</td>\n",
       "      <td>0.512360</td>\n",
       "      <td>0.395712</td>\n",
       "      <td>0.396809</td>\n",
       "      <td>0.371699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allenai/scibert_scivocab_uncased</th>\n",
       "      <td>0.556842</td>\n",
       "      <td>0.418162</td>\n",
       "      <td>0.424624</td>\n",
       "      <td>0.389233</td>\n",
       "      <td>0.486641</td>\n",
       "      <td>0.366889</td>\n",
       "      <td>0.370613</td>\n",
       "      <td>0.342096</td>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.390851</td>\n",
       "      <td>0.395784</td>\n",
       "      <td>0.364146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinai/phobert-large</th>\n",
       "      <td>0.556205</td>\n",
       "      <td>0.432335</td>\n",
       "      <td>0.430730</td>\n",
       "      <td>0.401390</td>\n",
       "      <td>0.526337</td>\n",
       "      <td>0.409172</td>\n",
       "      <td>0.406588</td>\n",
       "      <td>0.379919</td>\n",
       "      <td>0.540859</td>\n",
       "      <td>0.420435</td>\n",
       "      <td>0.418311</td>\n",
       "      <td>0.390360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rouge1_p  Rouge2_p  RougeL_p  RougeSU4_p  \\\n",
       "bert-base-multilingual-uncased    0.589949  0.468815  0.471425    0.440070   \n",
       "bert-large-uncased                0.577423  0.442054  0.440485    0.413317   \n",
       "gpt2                              0.592837  0.456343  0.459239    0.423710   \n",
       "facebook/bart-large               0.559149  0.418020  0.430839    0.388407   \n",
       "openai-gpt                        0.572291  0.433563  0.442683    0.404568   \n",
       "ctrl                              0.572195  0.439382  0.430547    0.413148   \n",
       "transfo-xl-wt103                  0.599472  0.454298  0.446087    0.423647   \n",
       "xlnet-large-cased                 0.585887  0.463378  0.466526    0.435221   \n",
       "xlm-mlm-enfr-1024                 0.573055  0.437195  0.430924    0.407219   \n",
       "distilbert-base-uncased           0.562064  0.423952  0.431258    0.395780   \n",
       "albert-large-v2                   0.576495  0.444851  0.446179    0.418132   \n",
       "allenai/scibert_scivocab_uncased  0.556842  0.418162  0.424624    0.389233   \n",
       "vinai/phobert-large               0.556205  0.432335  0.430730    0.401390   \n",
       "\n",
       "                                  Rouge1_r  Rouge2_r  RougeL_r  RougeSU4_r  \\\n",
       "bert-base-multilingual-uncased    0.531650  0.419202  0.422021    0.392686   \n",
       "bert-large-uncased                0.443022  0.337761  0.336407    0.315294   \n",
       "gpt2                              0.477464  0.366082  0.367362    0.339460   \n",
       "facebook/bart-large               0.472508  0.358028  0.366000    0.333033   \n",
       "openai-gpt                        0.466779  0.355695  0.361708    0.331607   \n",
       "ctrl                              0.516807  0.388970  0.382233    0.363626   \n",
       "transfo-xl-wt103                  0.411946  0.304241  0.302832    0.282794   \n",
       "xlnet-large-cased                 0.532594  0.418054  0.419548    0.392126   \n",
       "xlm-mlm-enfr-1024                 0.425831  0.316865  0.318507    0.294447   \n",
       "distilbert-base-uncased           0.495183  0.379124  0.383464    0.354335   \n",
       "albert-large-v2                   0.461067  0.356349  0.357276    0.334547   \n",
       "allenai/scibert_scivocab_uncased  0.486641  0.366889  0.370613    0.342096   \n",
       "vinai/phobert-large               0.526337  0.409172  0.406588    0.379919   \n",
       "\n",
       "                                  Rouge1_f  Rouge2_f  RougeL_f  RougeSU4_f  \n",
       "bert-base-multilingual-uncased    0.559284  0.442622  0.445357    0.415030  \n",
       "bert-large-uncased                0.501372  0.382934  0.381475    0.357712  \n",
       "gpt2                              0.528932  0.406259  0.408194    0.376934  \n",
       "facebook/bart-large               0.512190  0.385705  0.395781    0.358595  \n",
       "openai-gpt                        0.514178  0.390787  0.398120    0.364472  \n",
       "ctrl                              0.543093  0.412642  0.404954    0.386809  \n",
       "transfo-xl-wt103                  0.488324  0.364427  0.360758    0.339179  \n",
       "xlnet-large-cased                 0.557971  0.439551  0.441791    0.412551  \n",
       "xlm-mlm-enfr-1024                 0.488594  0.367429  0.366284    0.341771  \n",
       "distilbert-base-uncased           0.526508  0.400287  0.405959    0.373912  \n",
       "albert-large-v2                   0.512360  0.395712  0.396809    0.371699  \n",
       "allenai/scibert_scivocab_uncased  0.519380  0.390851  0.395784    0.364146  \n",
       "vinai/phobert-large               0.540859  0.420435  0.418311    0.390360  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score f, precision p, recall r\n",
    "df = pd.DataFrame(res, index = model_dict.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Analyzing others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T03:54:49.355952Z",
     "start_time": "2021-07-23T03:54:48.443216Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XH01.txt\n",
      "XH02.txt\n",
      "XH03.txt\n",
      "XH04.txt\n",
      "XH05.txt\n",
      "XH06.txt\n",
      "XH07.txt\n",
      "XH08.txt\n",
      "XH09.txt\n",
      "XH10.txt\n",
      "XH11.txt\n",
      "XH12.txt\n",
      "XH13.txt\n",
      "XH14.txt\n",
      "XH15.txt\n",
      "XH16.txt\n",
      "XH17.txt\n",
      "XH18.txt\n",
      "XH19.txt\n",
      "XH20.txt\n",
      "XH21.txt\n",
      "XH22.txt\n",
      "XH23.txt\n",
      "XH24.txt\n",
      "XH25.txt\n",
      "XH26.txt\n",
      "XH27.txt\n",
      "XH28.txt\n",
      "XH29.txt\n",
      "XH30.txt\n",
      "XH31.txt\n",
      "XH32.txt\n",
      "XH33.txt\n",
      "XH34.txt\n",
      "XH35.txt\n"
     ]
    }
   ],
   "source": [
    "#check utf-8 encode errors on datasets\n",
    "#plain vh020304, summary ct17, vh11\n",
    "'''\n",
    "os.chdir('E:/TextSummarization/donvanban/Summary_manual/Xa Hoi')\n",
    "for file in os.listdir():\n",
    "        print(file)\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = f\"{'E:/TextSummarization/donvanban/Summary_manual/Xa Hoi'}\\{file}\"\n",
    "            with open(file_path, 'r', encoding = 'utf-8') as f:\n",
    "                ftext = f.read()\n",
    "                ftext = ftext.replace('\\ufeff ','').replace('\\ufeff','').replace('\\n','')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T07:14:24.485103Z",
     "start_time": "2021-07-22T06:13:40.455849Z"
    },
    "code_folding": [
     8,
     13
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_transfo_xl.py:146: FutureWarning: The config parameter `tie_weight` is deprecated. Please use `tie_word_embeddings` instead.\n",
      "  FutureWarning,\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rouge1_p</th>\n",
       "      <th>Rouge2_p</th>\n",
       "      <th>RougeL_p</th>\n",
       "      <th>RougeSU4_p</th>\n",
       "      <th>Rouge1_r</th>\n",
       "      <th>Rouge2_r</th>\n",
       "      <th>RougeL_r</th>\n",
       "      <th>RougeSU4_r</th>\n",
       "      <th>Rouge1_f</th>\n",
       "      <th>Rouge2_f</th>\n",
       "      <th>RougeL_f</th>\n",
       "      <th>RougeSU4_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.606898</td>\n",
       "      <td>0.488426</td>\n",
       "      <td>0.511353</td>\n",
       "      <td>0.464321</td>\n",
       "      <td>0.460991</td>\n",
       "      <td>0.372269</td>\n",
       "      <td>0.387233</td>\n",
       "      <td>0.352674</td>\n",
       "      <td>0.523977</td>\n",
       "      <td>0.422509</td>\n",
       "      <td>0.440721</td>\n",
       "      <td>0.400868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-large-uncased</th>\n",
       "      <td>0.584729</td>\n",
       "      <td>0.466408</td>\n",
       "      <td>0.493596</td>\n",
       "      <td>0.447245</td>\n",
       "      <td>0.423522</td>\n",
       "      <td>0.342373</td>\n",
       "      <td>0.357176</td>\n",
       "      <td>0.327926</td>\n",
       "      <td>0.491238</td>\n",
       "      <td>0.394879</td>\n",
       "      <td>0.414449</td>\n",
       "      <td>0.378403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.591884</td>\n",
       "      <td>0.470366</td>\n",
       "      <td>0.495039</td>\n",
       "      <td>0.446783</td>\n",
       "      <td>0.428530</td>\n",
       "      <td>0.347310</td>\n",
       "      <td>0.361333</td>\n",
       "      <td>0.329626</td>\n",
       "      <td>0.497131</td>\n",
       "      <td>0.399578</td>\n",
       "      <td>0.417748</td>\n",
       "      <td>0.379365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large</th>\n",
       "      <td>0.571642</td>\n",
       "      <td>0.449727</td>\n",
       "      <td>0.474903</td>\n",
       "      <td>0.430690</td>\n",
       "      <td>0.441181</td>\n",
       "      <td>0.354861</td>\n",
       "      <td>0.371311</td>\n",
       "      <td>0.339761</td>\n",
       "      <td>0.498009</td>\n",
       "      <td>0.396701</td>\n",
       "      <td>0.416766</td>\n",
       "      <td>0.379860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt</th>\n",
       "      <td>0.603978</td>\n",
       "      <td>0.479673</td>\n",
       "      <td>0.500607</td>\n",
       "      <td>0.456440</td>\n",
       "      <td>0.413490</td>\n",
       "      <td>0.329500</td>\n",
       "      <td>0.342801</td>\n",
       "      <td>0.312312</td>\n",
       "      <td>0.490903</td>\n",
       "      <td>0.390652</td>\n",
       "      <td>0.406940</td>\n",
       "      <td>0.370865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctrl</th>\n",
       "      <td>0.570475</td>\n",
       "      <td>0.447075</td>\n",
       "      <td>0.464067</td>\n",
       "      <td>0.426458</td>\n",
       "      <td>0.449808</td>\n",
       "      <td>0.346983</td>\n",
       "      <td>0.360848</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.503006</td>\n",
       "      <td>0.390720</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>0.371790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfo-xl-wt103</th>\n",
       "      <td>0.637110</td>\n",
       "      <td>0.514270</td>\n",
       "      <td>0.536534</td>\n",
       "      <td>0.490145</td>\n",
       "      <td>0.418280</td>\n",
       "      <td>0.342160</td>\n",
       "      <td>0.355364</td>\n",
       "      <td>0.324859</td>\n",
       "      <td>0.505008</td>\n",
       "      <td>0.410921</td>\n",
       "      <td>0.427549</td>\n",
       "      <td>0.390742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlnet-large-cased</th>\n",
       "      <td>0.581520</td>\n",
       "      <td>0.467159</td>\n",
       "      <td>0.483462</td>\n",
       "      <td>0.448211</td>\n",
       "      <td>0.457777</td>\n",
       "      <td>0.366858</td>\n",
       "      <td>0.380432</td>\n",
       "      <td>0.350807</td>\n",
       "      <td>0.512282</td>\n",
       "      <td>0.410977</td>\n",
       "      <td>0.425803</td>\n",
       "      <td>0.393572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-mlm-enfr-1024</th>\n",
       "      <td>0.581030</td>\n",
       "      <td>0.458219</td>\n",
       "      <td>0.480850</td>\n",
       "      <td>0.434891</td>\n",
       "      <td>0.437265</td>\n",
       "      <td>0.350573</td>\n",
       "      <td>0.363914</td>\n",
       "      <td>0.333355</td>\n",
       "      <td>0.498999</td>\n",
       "      <td>0.397232</td>\n",
       "      <td>0.414288</td>\n",
       "      <td>0.377413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert-base-uncased</th>\n",
       "      <td>0.613016</td>\n",
       "      <td>0.491844</td>\n",
       "      <td>0.519021</td>\n",
       "      <td>0.472632</td>\n",
       "      <td>0.437599</td>\n",
       "      <td>0.359126</td>\n",
       "      <td>0.378010</td>\n",
       "      <td>0.345194</td>\n",
       "      <td>0.510664</td>\n",
       "      <td>0.415135</td>\n",
       "      <td>0.437432</td>\n",
       "      <td>0.398984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albert-large-v2</th>\n",
       "      <td>0.627881</td>\n",
       "      <td>0.513256</td>\n",
       "      <td>0.519786</td>\n",
       "      <td>0.489416</td>\n",
       "      <td>0.408149</td>\n",
       "      <td>0.330163</td>\n",
       "      <td>0.336601</td>\n",
       "      <td>0.312926</td>\n",
       "      <td>0.494713</td>\n",
       "      <td>0.401836</td>\n",
       "      <td>0.408601</td>\n",
       "      <td>0.381760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allenai/scibert_scivocab_uncased</th>\n",
       "      <td>0.593624</td>\n",
       "      <td>0.473396</td>\n",
       "      <td>0.494526</td>\n",
       "      <td>0.450434</td>\n",
       "      <td>0.431407</td>\n",
       "      <td>0.345968</td>\n",
       "      <td>0.359651</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>0.499680</td>\n",
       "      <td>0.399773</td>\n",
       "      <td>0.416440</td>\n",
       "      <td>0.380307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinai/phobert-large</th>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.440384</td>\n",
       "      <td>0.456234</td>\n",
       "      <td>0.417305</td>\n",
       "      <td>0.446242</td>\n",
       "      <td>0.354763</td>\n",
       "      <td>0.368099</td>\n",
       "      <td>0.336358</td>\n",
       "      <td>0.492991</td>\n",
       "      <td>0.392964</td>\n",
       "      <td>0.407455</td>\n",
       "      <td>0.372484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rouge1_p  Rouge2_p  RougeL_p  RougeSU4_p  \\\n",
       "bert-base-multilingual-uncased    0.606898  0.488426  0.511353    0.464321   \n",
       "bert-large-uncased                0.584729  0.466408  0.493596    0.447245   \n",
       "gpt2                              0.591884  0.470366  0.495039    0.446783   \n",
       "facebook/bart-large               0.571642  0.449727  0.474903    0.430690   \n",
       "openai-gpt                        0.603978  0.479673  0.500607    0.456440   \n",
       "ctrl                              0.570475  0.447075  0.464067    0.426458   \n",
       "transfo-xl-wt103                  0.637110  0.514270  0.536534    0.490145   \n",
       "xlnet-large-cased                 0.581520  0.467159  0.483462    0.448211   \n",
       "xlm-mlm-enfr-1024                 0.581030  0.458219  0.480850    0.434891   \n",
       "distilbert-base-uncased           0.613016  0.491844  0.519021    0.472632   \n",
       "albert-large-v2                   0.627881  0.513256  0.519786    0.489416   \n",
       "allenai/scibert_scivocab_uncased  0.593624  0.473396  0.494526    0.450434   \n",
       "vinai/phobert-large               0.550682  0.440384  0.456234    0.417305   \n",
       "\n",
       "                                  Rouge1_r  Rouge2_r  RougeL_r  RougeSU4_r  \\\n",
       "bert-base-multilingual-uncased    0.460991  0.372269  0.387233    0.352674   \n",
       "bert-large-uncased                0.423522  0.342373  0.357176    0.327926   \n",
       "gpt2                              0.428530  0.347310  0.361333    0.329626   \n",
       "facebook/bart-large               0.441181  0.354861  0.371311    0.339761   \n",
       "openai-gpt                        0.413490  0.329500  0.342801    0.312312   \n",
       "ctrl                              0.449808  0.346983  0.360848    0.329545   \n",
       "transfo-xl-wt103                  0.418280  0.342160  0.355364    0.324859   \n",
       "xlnet-large-cased                 0.457777  0.366858  0.380432    0.350807   \n",
       "xlm-mlm-enfr-1024                 0.437265  0.350573  0.363914    0.333355   \n",
       "distilbert-base-uncased           0.437599  0.359126  0.378010    0.345194   \n",
       "albert-large-v2                   0.408149  0.330163  0.336601    0.312926   \n",
       "allenai/scibert_scivocab_uncased  0.431407  0.345968  0.359651    0.329073   \n",
       "vinai/phobert-large               0.446242  0.354763  0.368099    0.336358   \n",
       "\n",
       "                                  Rouge1_f  Rouge2_f  RougeL_f  RougeSU4_f  \n",
       "bert-base-multilingual-uncased    0.523977  0.422509  0.440721    0.400868  \n",
       "bert-large-uncased                0.491238  0.394879  0.414449    0.378403  \n",
       "gpt2                              0.497131  0.399578  0.417748    0.379365  \n",
       "facebook/bart-large               0.498009  0.396701  0.416766    0.379860  \n",
       "openai-gpt                        0.490903  0.390652  0.406940    0.370865  \n",
       "ctrl                              0.503006  0.390720  0.406000    0.371790  \n",
       "transfo-xl-wt103                  0.505008  0.410921  0.427549    0.390742  \n",
       "xlnet-large-cased                 0.512282  0.410977  0.425803    0.393572  \n",
       "xlm-mlm-enfr-1024                 0.498999  0.397232  0.414288    0.377413  \n",
       "distilbert-base-uncased           0.510664  0.415135  0.437432    0.398984  \n",
       "albert-large-v2                   0.494713  0.401836  0.408601    0.381760  \n",
       "allenai/scibert_scivocab_uncased  0.499680  0.399773  0.416440    0.380307  \n",
       "vinai/phobert-large               0.492991  0.392964  0.407455    0.372484  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chinh tri\n",
    "idx = category[1]\n",
    "\n",
    "pathbody = 'E:/TextSummarization/donvanban/Plaintext/' + idx \n",
    "pathref = 'E:/TextSummarization/donvanban/Summary_manual/' + idx \n",
    "rootbody = loadtxt(pathbody)\n",
    "refbody = loadtxt(pathref, ref=True)\n",
    "\n",
    "res = {'Rouge1_p':[], 'Rouge2_p':[], 'RougeL_p':[], 'RougeSU4_p': [],\n",
    "        'Rouge1_r':[], 'Rouge2_r':[], 'RougeL_r':[], 'RougeSU4_r': [],\n",
    "        'Rouge1_f':[], 'Rouge2_f':[], 'RougeL_f':[], 'RougeSU4_f': [],\n",
    "      }\n",
    "\n",
    "for idx in model_dict.keys():    \n",
    "    model = Summarizer(model = idx, sentence_handler=CoreferenceHandler())\n",
    "    all_result = []\n",
    "    for jdx in range(len(rootbody)):\n",
    "        result = model(rootbody[jdx], ratio=2*len(refbody[jdx])/len(rootbody[jdx]))\n",
    "        all_result.append(result)\n",
    "    r_rouge = rouge_dist(all_result, refbody)\n",
    "    for ind in ['p', 'r', 'f']:\n",
    "        res['Rouge1_'+ind].append(r_rouge['rouge-1'][ind])\n",
    "        res['Rouge2_'+ind].append(r_rouge['rouge-2'][ind])\n",
    "        res['RougeL_'+ind].append(r_rouge['rouge-l'][ind])\n",
    "        res['RougeSU4_'+ind].append(r_rouge['rouge-su4'][ind])\n",
    "df = pd.DataFrame(res, index = model_dict.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T14:23:29.658089Z",
     "start_time": "2021-07-22T12:59:03.948560Z"
    },
    "code_folding": [
     8,
     13
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "c:\\users\\technical\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_transfo_xl.py:146: FutureWarning: The config parameter `tie_weight` is deprecated. Please use `tie_word_embeddings` instead.\n",
      "  FutureWarning,\n",
      "c:\\users\\technical\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039e2f7f244248318ec0fcd827779578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1452741, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2abd089fae349749d0001c046ab3bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1008321, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4da2e07abf4fc9a2d85d310c7b51c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=442, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc1bc78be844421b7050669a22f0139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=267967963, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fef35fbcdb4b6883653b02ae054ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6f2a072cea4ff4afd97722c3d14cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=685, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb13f3c524f94afc82c55b7d34eec15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=71509304, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baae15dc046435d9a19be30d668c1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=760289, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89f727f1e834e13b921de499e38e425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=385, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc3950151804987a0d438856c19c9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=442221694, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7077d854708240a9add8850ab872ac91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=227845, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a038a43d5bc440fab6f8003af76df7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=558, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a986c345aa46e88bac3f3038487ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1481467253, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bb6e69926144c8ae7b6944821b662b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=895321, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4240453793fc450b9bdab947d2238f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1135173, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rouge1_p</th>\n",
       "      <th>Rouge2_p</th>\n",
       "      <th>RougeL_p</th>\n",
       "      <th>RougeSU4_p</th>\n",
       "      <th>Rouge1_r</th>\n",
       "      <th>Rouge2_r</th>\n",
       "      <th>RougeL_r</th>\n",
       "      <th>RougeSU4_r</th>\n",
       "      <th>Rouge1_f</th>\n",
       "      <th>Rouge2_f</th>\n",
       "      <th>RougeL_f</th>\n",
       "      <th>RougeSU4_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.536254</td>\n",
       "      <td>0.368117</td>\n",
       "      <td>0.411873</td>\n",
       "      <td>0.349936</td>\n",
       "      <td>0.357484</td>\n",
       "      <td>0.245265</td>\n",
       "      <td>0.273270</td>\n",
       "      <td>0.230621</td>\n",
       "      <td>0.428990</td>\n",
       "      <td>0.294388</td>\n",
       "      <td>0.328552</td>\n",
       "      <td>0.278018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-large-uncased</th>\n",
       "      <td>0.543157</td>\n",
       "      <td>0.354487</td>\n",
       "      <td>0.399662</td>\n",
       "      <td>0.332533</td>\n",
       "      <td>0.313515</td>\n",
       "      <td>0.207422</td>\n",
       "      <td>0.228703</td>\n",
       "      <td>0.193525</td>\n",
       "      <td>0.397557</td>\n",
       "      <td>0.261709</td>\n",
       "      <td>0.290926</td>\n",
       "      <td>0.244663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.584382</td>\n",
       "      <td>0.411494</td>\n",
       "      <td>0.454490</td>\n",
       "      <td>0.389178</td>\n",
       "      <td>0.305186</td>\n",
       "      <td>0.210687</td>\n",
       "      <td>0.232031</td>\n",
       "      <td>0.195871</td>\n",
       "      <td>0.400970</td>\n",
       "      <td>0.278685</td>\n",
       "      <td>0.307218</td>\n",
       "      <td>0.260589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large</th>\n",
       "      <td>0.564344</td>\n",
       "      <td>0.378987</td>\n",
       "      <td>0.405870</td>\n",
       "      <td>0.356827</td>\n",
       "      <td>0.310637</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.221083</td>\n",
       "      <td>0.192267</td>\n",
       "      <td>0.400708</td>\n",
       "      <td>0.268044</td>\n",
       "      <td>0.286245</td>\n",
       "      <td>0.249888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt</th>\n",
       "      <td>0.570364</td>\n",
       "      <td>0.392951</td>\n",
       "      <td>0.418475</td>\n",
       "      <td>0.372536</td>\n",
       "      <td>0.318832</td>\n",
       "      <td>0.216094</td>\n",
       "      <td>0.232056</td>\n",
       "      <td>0.202027</td>\n",
       "      <td>0.409022</td>\n",
       "      <td>0.278845</td>\n",
       "      <td>0.298555</td>\n",
       "      <td>0.261981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctrl</th>\n",
       "      <td>0.486931</td>\n",
       "      <td>0.319998</td>\n",
       "      <td>0.358052</td>\n",
       "      <td>0.305114</td>\n",
       "      <td>0.367720</td>\n",
       "      <td>0.250466</td>\n",
       "      <td>0.272123</td>\n",
       "      <td>0.236195</td>\n",
       "      <td>0.419012</td>\n",
       "      <td>0.280995</td>\n",
       "      <td>0.309229</td>\n",
       "      <td>0.266267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfo-xl-wt103</th>\n",
       "      <td>0.583542</td>\n",
       "      <td>0.406037</td>\n",
       "      <td>0.456251</td>\n",
       "      <td>0.379149</td>\n",
       "      <td>0.262237</td>\n",
       "      <td>0.180220</td>\n",
       "      <td>0.199831</td>\n",
       "      <td>0.164662</td>\n",
       "      <td>0.361859</td>\n",
       "      <td>0.249638</td>\n",
       "      <td>0.277932</td>\n",
       "      <td>0.229607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlnet-large-cased</th>\n",
       "      <td>0.525853</td>\n",
       "      <td>0.352307</td>\n",
       "      <td>0.391537</td>\n",
       "      <td>0.331034</td>\n",
       "      <td>0.352453</td>\n",
       "      <td>0.244075</td>\n",
       "      <td>0.266600</td>\n",
       "      <td>0.227216</td>\n",
       "      <td>0.422036</td>\n",
       "      <td>0.288370</td>\n",
       "      <td>0.317210</td>\n",
       "      <td>0.269471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-mlm-enfr-1024</th>\n",
       "      <td>0.565920</td>\n",
       "      <td>0.388310</td>\n",
       "      <td>0.432547</td>\n",
       "      <td>0.367681</td>\n",
       "      <td>0.283499</td>\n",
       "      <td>0.191423</td>\n",
       "      <td>0.211416</td>\n",
       "      <td>0.177515</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.256433</td>\n",
       "      <td>0.284015</td>\n",
       "      <td>0.239433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert-base-uncased</th>\n",
       "      <td>0.539658</td>\n",
       "      <td>0.354672</td>\n",
       "      <td>0.397923</td>\n",
       "      <td>0.333094</td>\n",
       "      <td>0.315460</td>\n",
       "      <td>0.208399</td>\n",
       "      <td>0.230405</td>\n",
       "      <td>0.192865</td>\n",
       "      <td>0.398169</td>\n",
       "      <td>0.262536</td>\n",
       "      <td>0.291833</td>\n",
       "      <td>0.244286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albert-large-v2</th>\n",
       "      <td>0.511611</td>\n",
       "      <td>0.331997</td>\n",
       "      <td>0.383816</td>\n",
       "      <td>0.316015</td>\n",
       "      <td>0.310654</td>\n",
       "      <td>0.204976</td>\n",
       "      <td>0.234063</td>\n",
       "      <td>0.191911</td>\n",
       "      <td>0.386577</td>\n",
       "      <td>0.253463</td>\n",
       "      <td>0.290792</td>\n",
       "      <td>0.238802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allenai/scibert_scivocab_uncased</th>\n",
       "      <td>0.514710</td>\n",
       "      <td>0.331589</td>\n",
       "      <td>0.366447</td>\n",
       "      <td>0.309732</td>\n",
       "      <td>0.311058</td>\n",
       "      <td>0.199946</td>\n",
       "      <td>0.218265</td>\n",
       "      <td>0.185468</td>\n",
       "      <td>0.387771</td>\n",
       "      <td>0.249466</td>\n",
       "      <td>0.273580</td>\n",
       "      <td>0.232009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinai/phobert-large</th>\n",
       "      <td>0.475651</td>\n",
       "      <td>0.297596</td>\n",
       "      <td>0.341180</td>\n",
       "      <td>0.279125</td>\n",
       "      <td>0.392397</td>\n",
       "      <td>0.258927</td>\n",
       "      <td>0.286591</td>\n",
       "      <td>0.241661</td>\n",
       "      <td>0.430031</td>\n",
       "      <td>0.276918</td>\n",
       "      <td>0.311512</td>\n",
       "      <td>0.259045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rouge1_p  Rouge2_p  RougeL_p  RougeSU4_p  \\\n",
       "bert-base-multilingual-uncased    0.536254  0.368117  0.411873    0.349936   \n",
       "bert-large-uncased                0.543157  0.354487  0.399662    0.332533   \n",
       "gpt2                              0.584382  0.411494  0.454490    0.389178   \n",
       "facebook/bart-large               0.564344  0.378987  0.405870    0.356827   \n",
       "openai-gpt                        0.570364  0.392951  0.418475    0.372536   \n",
       "ctrl                              0.486931  0.319998  0.358052    0.305114   \n",
       "transfo-xl-wt103                  0.583542  0.406037  0.456251    0.379149   \n",
       "xlnet-large-cased                 0.525853  0.352307  0.391537    0.331034   \n",
       "xlm-mlm-enfr-1024                 0.565920  0.388310  0.432547    0.367681   \n",
       "distilbert-base-uncased           0.539658  0.354672  0.397923    0.333094   \n",
       "albert-large-v2                   0.511611  0.331997  0.383816    0.316015   \n",
       "allenai/scibert_scivocab_uncased  0.514710  0.331589  0.366447    0.309732   \n",
       "vinai/phobert-large               0.475651  0.297596  0.341180    0.279125   \n",
       "\n",
       "                                  Rouge1_r  Rouge2_r  RougeL_r  RougeSU4_r  \\\n",
       "bert-base-multilingual-uncased    0.357484  0.245265  0.273270    0.230621   \n",
       "bert-large-uncased                0.313515  0.207422  0.228703    0.193525   \n",
       "gpt2                              0.305186  0.210687  0.232031    0.195871   \n",
       "facebook/bart-large               0.310637  0.207347  0.221083    0.192267   \n",
       "openai-gpt                        0.318832  0.216094  0.232056    0.202027   \n",
       "ctrl                              0.367720  0.250466  0.272123    0.236195   \n",
       "transfo-xl-wt103                  0.262237  0.180220  0.199831    0.164662   \n",
       "xlnet-large-cased                 0.352453  0.244075  0.266600    0.227216   \n",
       "xlm-mlm-enfr-1024                 0.283499  0.191423  0.211416    0.177515   \n",
       "distilbert-base-uncased           0.315460  0.208399  0.230405    0.192865   \n",
       "albert-large-v2                   0.310654  0.204976  0.234063    0.191911   \n",
       "allenai/scibert_scivocab_uncased  0.311058  0.199946  0.218265    0.185468   \n",
       "vinai/phobert-large               0.392397  0.258927  0.286591    0.241661   \n",
       "\n",
       "                                  Rouge1_f  Rouge2_f  RougeL_f  RougeSU4_f  \n",
       "bert-base-multilingual-uncased    0.428990  0.294388  0.328552    0.278018  \n",
       "bert-large-uncased                0.397557  0.261709  0.290926    0.244663  \n",
       "gpt2                              0.400970  0.278685  0.307218    0.260589  \n",
       "facebook/bart-large               0.400708  0.268044  0.286245    0.249888  \n",
       "openai-gpt                        0.409022  0.278845  0.298555    0.261981  \n",
       "ctrl                              0.419012  0.280995  0.309229    0.266267  \n",
       "transfo-xl-wt103                  0.361859  0.249638  0.277932    0.229607  \n",
       "xlnet-large-cased                 0.422036  0.288370  0.317210    0.269471  \n",
       "xlm-mlm-enfr-1024                 0.377759  0.256433  0.284015    0.239433  \n",
       "distilbert-base-uncased           0.398169  0.262536  0.291833    0.244286  \n",
       "albert-large-v2                   0.386577  0.253463  0.290792    0.238802  \n",
       "allenai/scibert_scivocab_uncased  0.387771  0.249466  0.273580    0.232009  \n",
       "vinai/phobert-large               0.430031  0.276918  0.311512    0.259045  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#khoahockythuat\n",
    "idx = category[2]\n",
    "\n",
    "pathbody = 'E:/TextSummarization/donvanban/Plaintext/' + idx \n",
    "pathref = 'E:/TextSummarization/donvanban/Summary_manual/' + idx \n",
    "rootbody = loadtxt(pathbody)\n",
    "refbody = loadtxt(pathref, ref=True)\n",
    "\n",
    "res = {'Rouge1_p':[], 'Rouge2_p':[], 'RougeL_p':[], 'RougeSU4_p': [],\n",
    "        'Rouge1_r':[], 'Rouge2_r':[], 'RougeL_r':[], 'RougeSU4_r': [],\n",
    "        'Rouge1_f':[], 'Rouge2_f':[], 'RougeL_f':[], 'RougeSU4_f': [],\n",
    "      }\n",
    "\n",
    "for idx in model_dict.keys():    \n",
    "    model = Summarizer(model = idx, sentence_handler=CoreferenceHandler())\n",
    "    all_result = []\n",
    "    for jdx in range(len(rootbody)):\n",
    "        result = model(rootbody[jdx], ratio=2*len(refbody[jdx])/len(rootbody[jdx]))\n",
    "        all_result.append(result)\n",
    "    r_rouge = rouge_dist(all_result, refbody)\n",
    "    for ind in ['p', 'r', 'f']:\n",
    "        res['Rouge1_'+ind].append(r_rouge['rouge-1'][ind])\n",
    "        res['Rouge2_'+ind].append(r_rouge['rouge-2'][ind])\n",
    "        res['RougeL_'+ind].append(r_rouge['rouge-l'][ind])\n",
    "        res['RougeSU4_'+ind].append(r_rouge['rouge-su4'][ind])\n",
    "df = pd.DataFrame(res, index = model_dict.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T08:27:12.036362Z",
     "start_time": "2021-07-23T05:33:52.974766Z"
    },
    "code_folding": [
     7,
     12,
     19
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "c:\\users\\technical\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "c:\\users\\technical\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_transfo_xl.py:146: FutureWarning: The config parameter `tie_weight` is deprecated. Please use `tie_word_embeddings` instead.\n",
      "  FutureWarning,\n",
      "c:\\users\\technical\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rouge1_p</th>\n",
       "      <th>Rouge2_p</th>\n",
       "      <th>RougeL_p</th>\n",
       "      <th>RougeSU4_p</th>\n",
       "      <th>Rouge1_r</th>\n",
       "      <th>Rouge2_r</th>\n",
       "      <th>RougeL_r</th>\n",
       "      <th>RougeSU4_r</th>\n",
       "      <th>Rouge1_f</th>\n",
       "      <th>Rouge2_f</th>\n",
       "      <th>RougeL_f</th>\n",
       "      <th>RougeSU4_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.530388</td>\n",
       "      <td>0.356513</td>\n",
       "      <td>0.405619</td>\n",
       "      <td>0.333932</td>\n",
       "      <td>0.299726</td>\n",
       "      <td>0.200465</td>\n",
       "      <td>0.226252</td>\n",
       "      <td>0.185960</td>\n",
       "      <td>0.383010</td>\n",
       "      <td>0.256629</td>\n",
       "      <td>0.290477</td>\n",
       "      <td>0.238888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-large-uncased</th>\n",
       "      <td>0.492336</td>\n",
       "      <td>0.335471</td>\n",
       "      <td>0.383629</td>\n",
       "      <td>0.317570</td>\n",
       "      <td>0.276358</td>\n",
       "      <td>0.186792</td>\n",
       "      <td>0.212648</td>\n",
       "      <td>0.174713</td>\n",
       "      <td>0.354006</td>\n",
       "      <td>0.239968</td>\n",
       "      <td>0.273624</td>\n",
       "      <td>0.225414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.569050</td>\n",
       "      <td>0.409568</td>\n",
       "      <td>0.450531</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>0.280465</td>\n",
       "      <td>0.198937</td>\n",
       "      <td>0.219082</td>\n",
       "      <td>0.185618</td>\n",
       "      <td>0.375741</td>\n",
       "      <td>0.267798</td>\n",
       "      <td>0.294806</td>\n",
       "      <td>0.251289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large</th>\n",
       "      <td>0.518434</td>\n",
       "      <td>0.340215</td>\n",
       "      <td>0.400308</td>\n",
       "      <td>0.324933</td>\n",
       "      <td>0.286019</td>\n",
       "      <td>0.190926</td>\n",
       "      <td>0.217445</td>\n",
       "      <td>0.179552</td>\n",
       "      <td>0.368653</td>\n",
       "      <td>0.244590</td>\n",
       "      <td>0.281812</td>\n",
       "      <td>0.231295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt</th>\n",
       "      <td>0.570235</td>\n",
       "      <td>0.406665</td>\n",
       "      <td>0.456003</td>\n",
       "      <td>0.385390</td>\n",
       "      <td>0.300957</td>\n",
       "      <td>0.214085</td>\n",
       "      <td>0.238028</td>\n",
       "      <td>0.198954</td>\n",
       "      <td>0.393980</td>\n",
       "      <td>0.280502</td>\n",
       "      <td>0.312786</td>\n",
       "      <td>0.262431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctrl</th>\n",
       "      <td>0.560080</td>\n",
       "      <td>0.408440</td>\n",
       "      <td>0.443820</td>\n",
       "      <td>0.393660</td>\n",
       "      <td>0.302701</td>\n",
       "      <td>0.212283</td>\n",
       "      <td>0.233710</td>\n",
       "      <td>0.201295</td>\n",
       "      <td>0.393001</td>\n",
       "      <td>0.279368</td>\n",
       "      <td>0.306186</td>\n",
       "      <td>0.266379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfo-xl-wt103</th>\n",
       "      <td>0.529068</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0.417442</td>\n",
       "      <td>0.338171</td>\n",
       "      <td>0.252087</td>\n",
       "      <td>0.173870</td>\n",
       "      <td>0.200028</td>\n",
       "      <td>0.164086</td>\n",
       "      <td>0.341472</td>\n",
       "      <td>0.232726</td>\n",
       "      <td>0.270459</td>\n",
       "      <td>0.220959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlnet-large-cased</th>\n",
       "      <td>0.557770</td>\n",
       "      <td>0.394704</td>\n",
       "      <td>0.439757</td>\n",
       "      <td>0.380134</td>\n",
       "      <td>0.324983</td>\n",
       "      <td>0.228656</td>\n",
       "      <td>0.253074</td>\n",
       "      <td>0.217262</td>\n",
       "      <td>0.410683</td>\n",
       "      <td>0.289564</td>\n",
       "      <td>0.321264</td>\n",
       "      <td>0.276495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-mlm-enfr-1024</th>\n",
       "      <td>0.533898</td>\n",
       "      <td>0.359918</td>\n",
       "      <td>0.417652</td>\n",
       "      <td>0.339807</td>\n",
       "      <td>0.272771</td>\n",
       "      <td>0.183817</td>\n",
       "      <td>0.211893</td>\n",
       "      <td>0.171892</td>\n",
       "      <td>0.361069</td>\n",
       "      <td>0.243350</td>\n",
       "      <td>0.281148</td>\n",
       "      <td>0.228299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert-base-uncased</th>\n",
       "      <td>0.553853</td>\n",
       "      <td>0.388896</td>\n",
       "      <td>0.441077</td>\n",
       "      <td>0.372155</td>\n",
       "      <td>0.304812</td>\n",
       "      <td>0.213395</td>\n",
       "      <td>0.241322</td>\n",
       "      <td>0.201049</td>\n",
       "      <td>0.393217</td>\n",
       "      <td>0.275576</td>\n",
       "      <td>0.311963</td>\n",
       "      <td>0.261064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albert-large-v2</th>\n",
       "      <td>0.494522</td>\n",
       "      <td>0.321914</td>\n",
       "      <td>0.381601</td>\n",
       "      <td>0.310072</td>\n",
       "      <td>0.260761</td>\n",
       "      <td>0.171580</td>\n",
       "      <td>0.200217</td>\n",
       "      <td>0.161604</td>\n",
       "      <td>0.341467</td>\n",
       "      <td>0.223849</td>\n",
       "      <td>0.262635</td>\n",
       "      <td>0.212471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allenai/scibert_scivocab_uncased</th>\n",
       "      <td>0.546434</td>\n",
       "      <td>0.393624</td>\n",
       "      <td>0.432124</td>\n",
       "      <td>0.371290</td>\n",
       "      <td>0.304888</td>\n",
       "      <td>0.214258</td>\n",
       "      <td>0.234931</td>\n",
       "      <td>0.199418</td>\n",
       "      <td>0.391394</td>\n",
       "      <td>0.277479</td>\n",
       "      <td>0.304381</td>\n",
       "      <td>0.259474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinai/phobert-large</th>\n",
       "      <td>0.574526</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>0.459586</td>\n",
       "      <td>0.408102</td>\n",
       "      <td>0.327276</td>\n",
       "      <td>0.232051</td>\n",
       "      <td>0.253609</td>\n",
       "      <td>0.218065</td>\n",
       "      <td>0.417006</td>\n",
       "      <td>0.300528</td>\n",
       "      <td>0.326854</td>\n",
       "      <td>0.284246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rouge1_p  Rouge2_p  RougeL_p  RougeSU4_p  \\\n",
       "bert-base-multilingual-uncased    0.530388  0.356513  0.405619    0.333932   \n",
       "bert-large-uncased                0.492336  0.335471  0.383629    0.317570   \n",
       "gpt2                              0.569050  0.409568  0.450531    0.388871   \n",
       "facebook/bart-large               0.518434  0.340215  0.400308    0.324933   \n",
       "openai-gpt                        0.570235  0.406665  0.456003    0.385390   \n",
       "ctrl                              0.560080  0.408440  0.443820    0.393660   \n",
       "transfo-xl-wt103                  0.529068  0.351818  0.417442    0.338171   \n",
       "xlnet-large-cased                 0.557770  0.394704  0.439757    0.380134   \n",
       "xlm-mlm-enfr-1024                 0.533898  0.359918  0.417652    0.339807   \n",
       "distilbert-base-uncased           0.553853  0.388896  0.441077    0.372155   \n",
       "albert-large-v2                   0.494522  0.321914  0.381601    0.310072   \n",
       "allenai/scibert_scivocab_uncased  0.546434  0.393624  0.432124    0.371290   \n",
       "vinai/phobert-large               0.574526  0.426339  0.459586    0.408102   \n",
       "\n",
       "                                  Rouge1_r  Rouge2_r  RougeL_r  RougeSU4_r  \\\n",
       "bert-base-multilingual-uncased    0.299726  0.200465  0.226252    0.185960   \n",
       "bert-large-uncased                0.276358  0.186792  0.212648    0.174713   \n",
       "gpt2                              0.280465  0.198937  0.219082    0.185618   \n",
       "facebook/bart-large               0.286019  0.190926  0.217445    0.179552   \n",
       "openai-gpt                        0.300957  0.214085  0.238028    0.198954   \n",
       "ctrl                              0.302701  0.212283  0.233710    0.201295   \n",
       "transfo-xl-wt103                  0.252087  0.173870  0.200028    0.164086   \n",
       "xlnet-large-cased                 0.324983  0.228656  0.253074    0.217262   \n",
       "xlm-mlm-enfr-1024                 0.272771  0.183817  0.211893    0.171892   \n",
       "distilbert-base-uncased           0.304812  0.213395  0.241322    0.201049   \n",
       "albert-large-v2                   0.260761  0.171580  0.200217    0.161604   \n",
       "allenai/scibert_scivocab_uncased  0.304888  0.214258  0.234931    0.199418   \n",
       "vinai/phobert-large               0.327276  0.232051  0.253609    0.218065   \n",
       "\n",
       "                                  Rouge1_f  Rouge2_f  RougeL_f  RougeSU4_f  \n",
       "bert-base-multilingual-uncased    0.383010  0.256629  0.290477    0.238888  \n",
       "bert-large-uncased                0.354006  0.239968  0.273624    0.225414  \n",
       "gpt2                              0.375741  0.267798  0.294806    0.251289  \n",
       "facebook/bart-large               0.368653  0.244590  0.281812    0.231295  \n",
       "openai-gpt                        0.393980  0.280502  0.312786    0.262431  \n",
       "ctrl                              0.393001  0.279368  0.306186    0.266379  \n",
       "transfo-xl-wt103                  0.341472  0.232726  0.270459    0.220959  \n",
       "xlnet-large-cased                 0.410683  0.289564  0.321264    0.276495  \n",
       "xlm-mlm-enfr-1024                 0.361069  0.243350  0.281148    0.228299  \n",
       "distilbert-base-uncased           0.393217  0.275576  0.311963    0.261064  \n",
       "albert-large-v2                   0.341467  0.223849  0.262635    0.212471  \n",
       "allenai/scibert_scivocab_uncased  0.391394  0.277479  0.304381    0.259474  \n",
       "vinai/phobert-large               0.417006  0.300528  0.326854    0.284246  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = category[3]\n",
    "\n",
    "pathbody = 'E:/TextSummarization/donvanban/Plaintext/' + idx \n",
    "pathref = 'E:/TextSummarization/donvanban/Summary_manual/' + idx \n",
    "rootbody = loadtxt(pathbody)\n",
    "refbody = loadtxt(pathref, ref=True)\n",
    "\n",
    "res = {'Rouge1_p':[], 'Rouge2_p':[], 'RougeL_p':[], 'RougeSU4_p': [],\n",
    "        'Rouge1_r':[], 'Rouge2_r':[], 'RougeL_r':[], 'RougeSU4_r': [],\n",
    "        'Rouge1_f':[], 'Rouge2_f':[], 'RougeL_f':[], 'RougeSU4_f': [],\n",
    "      }\n",
    "\n",
    "for idx in model_dict.keys():    \n",
    "    model = Summarizer(model = idx, sentence_handler=CoreferenceHandler())\n",
    "    all_result = []\n",
    "    for jdx in range(len(rootbody)):\n",
    "        result = model(rootbody[jdx], ratio=2*len(refbody[jdx])/len(rootbody[jdx]))\n",
    "        all_result.append(result)\n",
    "    r_rouge = rouge_dist(all_result, refbody)\n",
    "    for ind in ['p', 'r', 'f']:\n",
    "        res['Rouge1_'+ind].append(r_rouge['rouge-1'][ind])\n",
    "        res['Rouge2_'+ind].append(r_rouge['rouge-2'][ind])\n",
    "        res['RougeL_'+ind].append(r_rouge['rouge-l'][ind])\n",
    "        res['RougeSU4_'+ind].append(r_rouge['rouge-su4'][ind])\n",
    "df = pd.DataFrame(res, index = model_dict.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T07:28:47.570139Z",
     "start_time": "2021-07-23T05:51:49.333787Z"
    },
    "code_folding": [
     7,
     12
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_transfo_xl.py:146: FutureWarning: The config parameter `tie_weight` is deprecated. Please use `tie_word_embeddings` instead.\n",
      "  FutureWarning,\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rouge1_p</th>\n",
       "      <th>Rouge2_p</th>\n",
       "      <th>RougeL_p</th>\n",
       "      <th>RougeSU4_p</th>\n",
       "      <th>Rouge1_r</th>\n",
       "      <th>Rouge2_r</th>\n",
       "      <th>RougeL_r</th>\n",
       "      <th>RougeSU4_r</th>\n",
       "      <th>Rouge1_f</th>\n",
       "      <th>Rouge2_f</th>\n",
       "      <th>RougeL_f</th>\n",
       "      <th>RougeSU4_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.419959</td>\n",
       "      <td>0.260637</td>\n",
       "      <td>0.318426</td>\n",
       "      <td>0.246730</td>\n",
       "      <td>0.251632</td>\n",
       "      <td>0.160160</td>\n",
       "      <td>0.189027</td>\n",
       "      <td>0.151359</td>\n",
       "      <td>0.314701</td>\n",
       "      <td>0.198403</td>\n",
       "      <td>0.237228</td>\n",
       "      <td>0.187620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-large-uncased</th>\n",
       "      <td>0.408568</td>\n",
       "      <td>0.254353</td>\n",
       "      <td>0.307670</td>\n",
       "      <td>0.246895</td>\n",
       "      <td>0.208488</td>\n",
       "      <td>0.126279</td>\n",
       "      <td>0.152615</td>\n",
       "      <td>0.120526</td>\n",
       "      <td>0.276090</td>\n",
       "      <td>0.168769</td>\n",
       "      <td>0.204026</td>\n",
       "      <td>0.161979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.433021</td>\n",
       "      <td>0.277941</td>\n",
       "      <td>0.332966</td>\n",
       "      <td>0.265527</td>\n",
       "      <td>0.215373</td>\n",
       "      <td>0.139819</td>\n",
       "      <td>0.165171</td>\n",
       "      <td>0.132079</td>\n",
       "      <td>0.287667</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.220808</td>\n",
       "      <td>0.176408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large</th>\n",
       "      <td>0.421589</td>\n",
       "      <td>0.270862</td>\n",
       "      <td>0.328721</td>\n",
       "      <td>0.260702</td>\n",
       "      <td>0.225046</td>\n",
       "      <td>0.150777</td>\n",
       "      <td>0.175961</td>\n",
       "      <td>0.143450</td>\n",
       "      <td>0.293448</td>\n",
       "      <td>0.193719</td>\n",
       "      <td>0.229222</td>\n",
       "      <td>0.185067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt</th>\n",
       "      <td>0.443905</td>\n",
       "      <td>0.292327</td>\n",
       "      <td>0.340738</td>\n",
       "      <td>0.282514</td>\n",
       "      <td>0.237590</td>\n",
       "      <td>0.161473</td>\n",
       "      <td>0.181809</td>\n",
       "      <td>0.153630</td>\n",
       "      <td>0.309518</td>\n",
       "      <td>0.208034</td>\n",
       "      <td>0.237105</td>\n",
       "      <td>0.199029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctrl</th>\n",
       "      <td>0.407358</td>\n",
       "      <td>0.253398</td>\n",
       "      <td>0.304184</td>\n",
       "      <td>0.241371</td>\n",
       "      <td>0.240232</td>\n",
       "      <td>0.144653</td>\n",
       "      <td>0.171588</td>\n",
       "      <td>0.136343</td>\n",
       "      <td>0.302229</td>\n",
       "      <td>0.184171</td>\n",
       "      <td>0.219409</td>\n",
       "      <td>0.174255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfo-xl-wt103</th>\n",
       "      <td>0.438544</td>\n",
       "      <td>0.266815</td>\n",
       "      <td>0.335239</td>\n",
       "      <td>0.255635</td>\n",
       "      <td>0.218167</td>\n",
       "      <td>0.138108</td>\n",
       "      <td>0.165696</td>\n",
       "      <td>0.131283</td>\n",
       "      <td>0.291379</td>\n",
       "      <td>0.182007</td>\n",
       "      <td>0.221776</td>\n",
       "      <td>0.173476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlnet-large-cased</th>\n",
       "      <td>0.381087</td>\n",
       "      <td>0.219418</td>\n",
       "      <td>0.273056</td>\n",
       "      <td>0.210942</td>\n",
       "      <td>0.245915</td>\n",
       "      <td>0.141625</td>\n",
       "      <td>0.172453</td>\n",
       "      <td>0.135256</td>\n",
       "      <td>0.298931</td>\n",
       "      <td>0.172141</td>\n",
       "      <td>0.211396</td>\n",
       "      <td>0.164826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-mlm-enfr-1024</th>\n",
       "      <td>0.410395</td>\n",
       "      <td>0.244495</td>\n",
       "      <td>0.307248</td>\n",
       "      <td>0.234934</td>\n",
       "      <td>0.220099</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.161009</td>\n",
       "      <td>0.124493</td>\n",
       "      <td>0.286530</td>\n",
       "      <td>0.170255</td>\n",
       "      <td>0.211293</td>\n",
       "      <td>0.162746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert-base-uncased</th>\n",
       "      <td>0.421393</td>\n",
       "      <td>0.253721</td>\n",
       "      <td>0.314517</td>\n",
       "      <td>0.246651</td>\n",
       "      <td>0.229169</td>\n",
       "      <td>0.145959</td>\n",
       "      <td>0.174464</td>\n",
       "      <td>0.139197</td>\n",
       "      <td>0.296883</td>\n",
       "      <td>0.185313</td>\n",
       "      <td>0.224433</td>\n",
       "      <td>0.177962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albert-large-v2</th>\n",
       "      <td>0.418416</td>\n",
       "      <td>0.259309</td>\n",
       "      <td>0.312746</td>\n",
       "      <td>0.243374</td>\n",
       "      <td>0.239711</td>\n",
       "      <td>0.154806</td>\n",
       "      <td>0.178794</td>\n",
       "      <td>0.144428</td>\n",
       "      <td>0.304801</td>\n",
       "      <td>0.193871</td>\n",
       "      <td>0.227518</td>\n",
       "      <td>0.181278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allenai/scibert_scivocab_uncased</th>\n",
       "      <td>0.409715</td>\n",
       "      <td>0.251090</td>\n",
       "      <td>0.309264</td>\n",
       "      <td>0.239114</td>\n",
       "      <td>0.237339</td>\n",
       "      <td>0.151423</td>\n",
       "      <td>0.179944</td>\n",
       "      <td>0.144180</td>\n",
       "      <td>0.300567</td>\n",
       "      <td>0.188917</td>\n",
       "      <td>0.227511</td>\n",
       "      <td>0.179891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinai/phobert-large</th>\n",
       "      <td>0.424669</td>\n",
       "      <td>0.265593</td>\n",
       "      <td>0.323493</td>\n",
       "      <td>0.249347</td>\n",
       "      <td>0.260240</td>\n",
       "      <td>0.170680</td>\n",
       "      <td>0.198443</td>\n",
       "      <td>0.160637</td>\n",
       "      <td>0.322717</td>\n",
       "      <td>0.207812</td>\n",
       "      <td>0.245988</td>\n",
       "      <td>0.195395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rouge1_p  Rouge2_p  RougeL_p  RougeSU4_p  \\\n",
       "bert-base-multilingual-uncased    0.419959  0.260637  0.318426    0.246730   \n",
       "bert-large-uncased                0.408568  0.254353  0.307670    0.246895   \n",
       "gpt2                              0.433021  0.277941  0.332966    0.265527   \n",
       "facebook/bart-large               0.421589  0.270862  0.328721    0.260702   \n",
       "openai-gpt                        0.443905  0.292327  0.340738    0.282514   \n",
       "ctrl                              0.407358  0.253398  0.304184    0.241371   \n",
       "transfo-xl-wt103                  0.438544  0.266815  0.335239    0.255635   \n",
       "xlnet-large-cased                 0.381087  0.219418  0.273056    0.210942   \n",
       "xlm-mlm-enfr-1024                 0.410395  0.244495  0.307248    0.234934   \n",
       "distilbert-base-uncased           0.421393  0.253721  0.314517    0.246651   \n",
       "albert-large-v2                   0.418416  0.259309  0.312746    0.243374   \n",
       "allenai/scibert_scivocab_uncased  0.409715  0.251090  0.309264    0.239114   \n",
       "vinai/phobert-large               0.424669  0.265593  0.323493    0.249347   \n",
       "\n",
       "                                  Rouge1_r  Rouge2_r  RougeL_r  RougeSU4_r  \\\n",
       "bert-base-multilingual-uncased    0.251632  0.160160  0.189027    0.151359   \n",
       "bert-large-uncased                0.208488  0.126279  0.152615    0.120526   \n",
       "gpt2                              0.215373  0.139819  0.165171    0.132079   \n",
       "facebook/bart-large               0.225046  0.150777  0.175961    0.143450   \n",
       "openai-gpt                        0.237590  0.161473  0.181809    0.153630   \n",
       "ctrl                              0.240232  0.144653  0.171588    0.136343   \n",
       "transfo-xl-wt103                  0.218167  0.138108  0.165696    0.131283   \n",
       "xlnet-large-cased                 0.245915  0.141625  0.172453    0.135256   \n",
       "xlm-mlm-enfr-1024                 0.220099  0.130600  0.161009    0.124493   \n",
       "distilbert-base-uncased           0.229169  0.145959  0.174464    0.139197   \n",
       "albert-large-v2                   0.239711  0.154806  0.178794    0.144428   \n",
       "allenai/scibert_scivocab_uncased  0.237339  0.151423  0.179944    0.144180   \n",
       "vinai/phobert-large               0.260240  0.170680  0.198443    0.160637   \n",
       "\n",
       "                                  Rouge1_f  Rouge2_f  RougeL_f  RougeSU4_f  \n",
       "bert-base-multilingual-uncased    0.314701  0.198403  0.237228    0.187620  \n",
       "bert-large-uncased                0.276090  0.168769  0.204026    0.161979  \n",
       "gpt2                              0.287667  0.186047  0.220808    0.176408  \n",
       "facebook/bart-large               0.293448  0.193719  0.229222    0.185067  \n",
       "openai-gpt                        0.309518  0.208034  0.237105    0.199029  \n",
       "ctrl                              0.302229  0.184171  0.219409    0.174255  \n",
       "transfo-xl-wt103                  0.291379  0.182007  0.221776    0.173476  \n",
       "xlnet-large-cased                 0.298931  0.172141  0.211396    0.164826  \n",
       "xlm-mlm-enfr-1024                 0.286530  0.170255  0.211293    0.162746  \n",
       "distilbert-base-uncased           0.296883  0.185313  0.224433    0.177962  \n",
       "albert-large-v2                   0.304801  0.193871  0.227518    0.181278  \n",
       "allenai/scibert_scivocab_uncased  0.300567  0.188917  0.227511    0.179891  \n",
       "vinai/phobert-large               0.322717  0.207812  0.245988    0.195395  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = category[4]\n",
    "\n",
    "pathbody = 'E:/TextSummarization/donvanban/Plaintext/' + idx \n",
    "pathref = 'E:/TextSummarization/donvanban/Summary_manual/' + idx \n",
    "rootbody = loadtxt(pathbody)\n",
    "refbody = loadtxt(pathref, ref=True)\n",
    "\n",
    "res = {'Rouge1_p':[], 'Rouge2_p':[], 'RougeL_p':[], 'RougeSU4_p': [],\n",
    "        'Rouge1_r':[], 'Rouge2_r':[], 'RougeL_r':[], 'RougeSU4_r': [],\n",
    "        'Rouge1_f':[], 'Rouge2_f':[], 'RougeL_f':[], 'RougeSU4_f': [],\n",
    "      }\n",
    "\n",
    "for idx in model_dict.keys():    \n",
    "    model = Summarizer(model = idx, sentence_handler=CoreferenceHandler())\n",
    "    all_result = []\n",
    "    for jdx in range(len(rootbody)):\n",
    "        result = model(rootbody[jdx], ratio=2*len(refbody[jdx])/len(rootbody[jdx]))\n",
    "        all_result.append(result)\n",
    "    r_rouge = rouge_dist(all_result, refbody)\n",
    "    for ind in ['p', 'r', 'f']:\n",
    "        res['Rouge1_'+ind].append(r_rouge['rouge-1'][ind])\n",
    "        res['Rouge2_'+ind].append(r_rouge['rouge-2'][ind])\n",
    "        res['RougeL_'+ind].append(r_rouge['rouge-l'][ind])\n",
    "        res['RougeSU4_'+ind].append(r_rouge['rouge-su4'][ind])\n",
    "df = pd.DataFrame(res, index = model_dict.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T10:23:53.443017Z",
     "start_time": "2021-07-23T08:27:12.041905Z"
    },
    "code_folding": [
     7,
     12
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "c:\\users\\technical\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_transfo_xl.py:146: FutureWarning: The config parameter `tie_weight` is deprecated. Please use `tie_word_embeddings` instead.\n",
      "  FutureWarning,\n",
      "c:\\users\\technical\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rouge1_p</th>\n",
       "      <th>Rouge2_p</th>\n",
       "      <th>RougeL_p</th>\n",
       "      <th>RougeSU4_p</th>\n",
       "      <th>Rouge1_r</th>\n",
       "      <th>Rouge2_r</th>\n",
       "      <th>RougeL_r</th>\n",
       "      <th>RougeSU4_r</th>\n",
       "      <th>Rouge1_f</th>\n",
       "      <th>Rouge2_f</th>\n",
       "      <th>RougeL_f</th>\n",
       "      <th>RougeSU4_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.500717</td>\n",
       "      <td>0.335891</td>\n",
       "      <td>0.377074</td>\n",
       "      <td>0.319064</td>\n",
       "      <td>0.304166</td>\n",
       "      <td>0.211028</td>\n",
       "      <td>0.231594</td>\n",
       "      <td>0.198776</td>\n",
       "      <td>0.378443</td>\n",
       "      <td>0.259207</td>\n",
       "      <td>0.286948</td>\n",
       "      <td>0.244950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-large-uncased</th>\n",
       "      <td>0.503477</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.380821</td>\n",
       "      <td>0.328923</td>\n",
       "      <td>0.258243</td>\n",
       "      <td>0.176876</td>\n",
       "      <td>0.195496</td>\n",
       "      <td>0.165626</td>\n",
       "      <td>0.341384</td>\n",
       "      <td>0.233719</td>\n",
       "      <td>0.258361</td>\n",
       "      <td>0.220315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.540692</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.423641</td>\n",
       "      <td>0.365884</td>\n",
       "      <td>0.267464</td>\n",
       "      <td>0.189232</td>\n",
       "      <td>0.209020</td>\n",
       "      <td>0.178608</td>\n",
       "      <td>0.357890</td>\n",
       "      <td>0.252715</td>\n",
       "      <td>0.279927</td>\n",
       "      <td>0.240039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large</th>\n",
       "      <td>0.531781</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.416920</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.294335</td>\n",
       "      <td>0.207849</td>\n",
       "      <td>0.230653</td>\n",
       "      <td>0.197494</td>\n",
       "      <td>0.378934</td>\n",
       "      <td>0.264659</td>\n",
       "      <td>0.296998</td>\n",
       "      <td>0.252698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai-gpt</th>\n",
       "      <td>0.487840</td>\n",
       "      <td>0.317110</td>\n",
       "      <td>0.370046</td>\n",
       "      <td>0.306068</td>\n",
       "      <td>0.267715</td>\n",
       "      <td>0.175316</td>\n",
       "      <td>0.201075</td>\n",
       "      <td>0.165604</td>\n",
       "      <td>0.345712</td>\n",
       "      <td>0.225798</td>\n",
       "      <td>0.260565</td>\n",
       "      <td>0.214921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctrl</th>\n",
       "      <td>0.507409</td>\n",
       "      <td>0.356920</td>\n",
       "      <td>0.376180</td>\n",
       "      <td>0.341621</td>\n",
       "      <td>0.305062</td>\n",
       "      <td>0.211551</td>\n",
       "      <td>0.223330</td>\n",
       "      <td>0.199203</td>\n",
       "      <td>0.381038</td>\n",
       "      <td>0.265649</td>\n",
       "      <td>0.280269</td>\n",
       "      <td>0.251660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfo-xl-wt103</th>\n",
       "      <td>0.525901</td>\n",
       "      <td>0.352383</td>\n",
       "      <td>0.398021</td>\n",
       "      <td>0.334715</td>\n",
       "      <td>0.245627</td>\n",
       "      <td>0.168283</td>\n",
       "      <td>0.186899</td>\n",
       "      <td>0.156607</td>\n",
       "      <td>0.334856</td>\n",
       "      <td>0.227786</td>\n",
       "      <td>0.254359</td>\n",
       "      <td>0.213378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlnet-large-cased</th>\n",
       "      <td>0.519272</td>\n",
       "      <td>0.374568</td>\n",
       "      <td>0.402207</td>\n",
       "      <td>0.353530</td>\n",
       "      <td>0.294641</td>\n",
       "      <td>0.215823</td>\n",
       "      <td>0.229381</td>\n",
       "      <td>0.200726</td>\n",
       "      <td>0.375959</td>\n",
       "      <td>0.273854</td>\n",
       "      <td>0.292148</td>\n",
       "      <td>0.256065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-mlm-enfr-1024</th>\n",
       "      <td>0.524133</td>\n",
       "      <td>0.371204</td>\n",
       "      <td>0.409127</td>\n",
       "      <td>0.353783</td>\n",
       "      <td>0.306791</td>\n",
       "      <td>0.223627</td>\n",
       "      <td>0.241264</td>\n",
       "      <td>0.209859</td>\n",
       "      <td>0.387038</td>\n",
       "      <td>0.279109</td>\n",
       "      <td>0.303533</td>\n",
       "      <td>0.263446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert-base-uncased</th>\n",
       "      <td>0.504549</td>\n",
       "      <td>0.329222</td>\n",
       "      <td>0.376833</td>\n",
       "      <td>0.316757</td>\n",
       "      <td>0.288143</td>\n",
       "      <td>0.195924</td>\n",
       "      <td>0.215930</td>\n",
       "      <td>0.185842</td>\n",
       "      <td>0.366806</td>\n",
       "      <td>0.245656</td>\n",
       "      <td>0.274543</td>\n",
       "      <td>0.234249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albert-large-v2</th>\n",
       "      <td>0.480543</td>\n",
       "      <td>0.307515</td>\n",
       "      <td>0.354598</td>\n",
       "      <td>0.292581</td>\n",
       "      <td>0.256889</td>\n",
       "      <td>0.165319</td>\n",
       "      <td>0.190731</td>\n",
       "      <td>0.155124</td>\n",
       "      <td>0.334800</td>\n",
       "      <td>0.215036</td>\n",
       "      <td>0.248044</td>\n",
       "      <td>0.202751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allenai/scibert_scivocab_uncased</th>\n",
       "      <td>0.485229</td>\n",
       "      <td>0.323698</td>\n",
       "      <td>0.363979</td>\n",
       "      <td>0.305105</td>\n",
       "      <td>0.268949</td>\n",
       "      <td>0.178652</td>\n",
       "      <td>0.200715</td>\n",
       "      <td>0.165867</td>\n",
       "      <td>0.346077</td>\n",
       "      <td>0.230235</td>\n",
       "      <td>0.258746</td>\n",
       "      <td>0.214904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinai/phobert-large</th>\n",
       "      <td>0.486945</td>\n",
       "      <td>0.320247</td>\n",
       "      <td>0.364166</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.307452</td>\n",
       "      <td>0.208641</td>\n",
       "      <td>0.230677</td>\n",
       "      <td>0.194424</td>\n",
       "      <td>0.376920</td>\n",
       "      <td>0.252668</td>\n",
       "      <td>0.282443</td>\n",
       "      <td>0.236862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rouge1_p  Rouge2_p  RougeL_p  RougeSU4_p  \\\n",
       "bert-base-multilingual-uncased    0.500717  0.335891  0.377074    0.319064   \n",
       "bert-large-uncased                0.503477  0.344400  0.380821    0.328923   \n",
       "gpt2                              0.540692  0.380299  0.423641    0.365884   \n",
       "facebook/bart-large               0.531781  0.364206  0.416920    0.350735   \n",
       "openai-gpt                        0.487840  0.317110  0.370046    0.306068   \n",
       "ctrl                              0.507409  0.356920  0.376180    0.341621   \n",
       "transfo-xl-wt103                  0.525901  0.352383  0.398021    0.334715   \n",
       "xlnet-large-cased                 0.519272  0.374568  0.402207    0.353530   \n",
       "xlm-mlm-enfr-1024                 0.524133  0.371204  0.409127    0.353783   \n",
       "distilbert-base-uncased           0.504549  0.329222  0.376833    0.316757   \n",
       "albert-large-v2                   0.480543  0.307515  0.354598    0.292581   \n",
       "allenai/scibert_scivocab_uncased  0.485229  0.323698  0.363979    0.305105   \n",
       "vinai/phobert-large               0.486945  0.320247  0.364166    0.303000   \n",
       "\n",
       "                                  Rouge1_r  Rouge2_r  RougeL_r  RougeSU4_r  \\\n",
       "bert-base-multilingual-uncased    0.304166  0.211028  0.231594    0.198776   \n",
       "bert-large-uncased                0.258243  0.176876  0.195496    0.165626   \n",
       "gpt2                              0.267464  0.189232  0.209020    0.178608   \n",
       "facebook/bart-large               0.294335  0.207849  0.230653    0.197494   \n",
       "openai-gpt                        0.267715  0.175316  0.201075    0.165604   \n",
       "ctrl                              0.305062  0.211551  0.223330    0.199203   \n",
       "transfo-xl-wt103                  0.245627  0.168283  0.186899    0.156607   \n",
       "xlnet-large-cased                 0.294641  0.215823  0.229381    0.200726   \n",
       "xlm-mlm-enfr-1024                 0.306791  0.223627  0.241264    0.209859   \n",
       "distilbert-base-uncased           0.288143  0.195924  0.215930    0.185842   \n",
       "albert-large-v2                   0.256889  0.165319  0.190731    0.155124   \n",
       "allenai/scibert_scivocab_uncased  0.268949  0.178652  0.200715    0.165867   \n",
       "vinai/phobert-large               0.307452  0.208641  0.230677    0.194424   \n",
       "\n",
       "                                  Rouge1_f  Rouge2_f  RougeL_f  RougeSU4_f  \n",
       "bert-base-multilingual-uncased    0.378443  0.259207  0.286948    0.244950  \n",
       "bert-large-uncased                0.341384  0.233719  0.258361    0.220315  \n",
       "gpt2                              0.357890  0.252715  0.279927    0.240039  \n",
       "facebook/bart-large               0.378934  0.264659  0.296998    0.252698  \n",
       "openai-gpt                        0.345712  0.225798  0.260565    0.214921  \n",
       "ctrl                              0.381038  0.265649  0.280269    0.251660  \n",
       "transfo-xl-wt103                  0.334856  0.227786  0.254359    0.213378  \n",
       "xlnet-large-cased                 0.375959  0.273854  0.292148    0.256065  \n",
       "xlm-mlm-enfr-1024                 0.387038  0.279109  0.303533    0.263446  \n",
       "distilbert-base-uncased           0.366806  0.245656  0.274543    0.234249  \n",
       "albert-large-v2                   0.334800  0.215036  0.248044    0.202751  \n",
       "allenai/scibert_scivocab_uncased  0.346077  0.230235  0.258746    0.214904  \n",
       "vinai/phobert-large               0.376920  0.252668  0.282443    0.236862  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = category[5]\n",
    "\n",
    "pathbody = 'E:/TextSummarization/donvanban/Plaintext/' + idx \n",
    "pathref = 'E:/TextSummarization/donvanban/Summary_manual/' + idx \n",
    "rootbody = loadtxt(pathbody)\n",
    "refbody = loadtxt(pathref, ref=True)\n",
    "\n",
    "res = {'Rouge1_p':[], 'Rouge2_p':[], 'RougeL_p':[], 'RougeSU4_p': [],\n",
    "        'Rouge1_r':[], 'Rouge2_r':[], 'RougeL_r':[], 'RougeSU4_r': [],\n",
    "        'Rouge1_f':[], 'Rouge2_f':[], 'RougeL_f':[], 'RougeSU4_f': [],\n",
    "      }\n",
    "\n",
    "for idx in model_dict.keys():    \n",
    "    model = Summarizer(model = idx, sentence_handler=CoreferenceHandler())\n",
    "    all_result = []\n",
    "    for jdx in range(len(rootbody)):\n",
    "        result = model(rootbody[jdx], ratio=2*len(refbody[jdx])/len(rootbody[jdx]))\n",
    "        all_result.append(result)\n",
    "    r_rouge = rouge_dist(all_result, refbody)\n",
    "    for ind in ['p', 'r', 'f']:\n",
    "        res['Rouge1_'+ind].append(r_rouge['rouge-1'][ind])\n",
    "        res['Rouge2_'+ind].append(r_rouge['rouge-2'][ind])\n",
    "        res['RougeL_'+ind].append(r_rouge['rouge-l'][ind])\n",
    "        res['RougeSU4_'+ind].append(r_rouge['rouge-su4'][ind])\n",
    "df = pd.DataFrame(res, index = model_dict.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Summarizer(\n",
    "    model: This gets used by the hugging face bert library to load the model, you can supply a custom trained model here\n",
    "    custom_model: If you have a pre-trained model, you can add the model class here.\n",
    "    custom_tokenizer:  If you have a custom tokenizer, you can add the tokenizer here.\n",
    "    hidden: Needs to be negative, but allows you to pick which layer you want the embeddings to come from.\n",
    "    reduce_option: It can be 'mean', 'median', or 'max'. This reduces the embedding layer for pooling.\n",
    "    sentence_handler: The handler to process sentences. If want to use coreference, instantiate and pass CoreferenceHandler instance)\n",
    "model(body: str # The string body that you want to summarize\n",
    "    ratio: float # The ratio of sentences that you want for the final summary\n",
    "    min_length: int # Parameter to specify to remove sentences that are less than 40 characters\n",
    "    max_length: int # Parameter to specify to remove sentences greater than the max length,\n",
    "    num_sentences: Number of sentences to use. Overrides ratio if supplied)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:43:08.778428Z",
     "start_time": "2021-07-22T05:43:08.767458Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "body = '''\n",
    "Shiba Inu (柴犬 (sài khuyển)) là loại chó nhỏ nhất trong sáu giống chó nguyên thủy và riêng biệt đến từ Nhật Bản. Chúng là một giống chó nhỏ, nhanh nhẹn và thích hợp với địa hình miền núi, Shiba Inu ban đầu được nuôi để săn bắt. Nó gần giống nhưng nhỏ hơn so với giống Akita Inu. Đây là một trong số ít giống chó cổ xưa vẫn còn tồn tại cho đến ngày nay.\n",
    "Shiba là một trong sáu giống chó điển hình của Nhật Bản, cũng như Hokkaido, Kishu, Shikoku, Kai và Akita. Trong những giống chó này, Shiba là nhỏ nhất.\n",
    "Inu hoặc ken (犬 - Hán Việt: khuyển) trong tiếng Nhật có nghĩa là con chó, nhưng nguồn gốc của từ \"Shiba\" vẫn chưa rõ. Từ Shiba (柴 - Hán Việt: sài) có nghĩa là cây bụi trong tiếng Nhật, đề cập đến một loại cây hoặc cây bụi có lá chuyển sang màu đỏ vào mùa thu. Điều này khiến cho một số người tin rằng Shiba được đặt tên như thế là vì loài chó này được sử dụng để săn mồi trong các bụi cây, hoặc có thể là do màu sắc phổ biến nhất của Shiba Inu là màu đỏ tương tự như của các cây bụi. Tuy nhiên, trong một phương ngữ Nagano cổ, từ Shiba cũng có ý nghĩa là nhỏ, do đó cái tên có thể nói đến tầm vóc nhỏ bé của con chó. Do đó, Shiba Inu đôi khi được dịch là \"Little Brushwood Dog\", tức \"Chó bụi nhỏ\".\n",
    "Khung hình của Shiba nhỏ gọn với cơ bắp phát triển tốt. Con đực có chiều cao từ 35 đến 43 cm (14 đến 17 in). Đối với con cái là 33 đến 41 cm (13 đến 16 in). Trọng lượng trung bình ở kích thước tương thích là khoảng 10 kg (22 lb) đối với con đực và 8 kg (18 lb) đối với con cái. Xương vừa phải.\n",
    "Lớp lông: Có hai lớp lông với lớp ngoài cứng và thẳng cùng một lớp trong mềm mại và dày. Lông mao ngắn và thậm chí trên mặt, tai và chân giống cáo. Lông bảo vệ xù ra khỏi cơ thể chiều dài khoảng 4 đến 5 cm (1 1⁄2 đến 2 in) ở vai. Lông đuôi hơi dài và xù ra. Shiba có thể có màu đỏ, đen và nâu, hoặc màu vừng (màu đỏ với những sợi ngã sang đen), với một lớp lông lót màu kem, màu da bò, hoặc màu xám. Nó cũng có thể có màu trắng (kem), mặc dù màu này được xem là một\"lỗi nghiêm trọng\"bởi Hiệp hội chó giống Mỹ và không bao giờ được nuôi trong các chương trình. Ngược lại, một lớp lông màu trắng (kem) là hoàn toàn chấp nhận được theo tiêu chuẩn giống chó Anh.\n",
    "Urajiro (màu kem trắng) có ở các bộ phận sau trên tất cả các vùng lông: ở hai bên mõm, trên má, bên trong tai, trên hàm dưới và ở chỗ cổ họng, bên trong chân, trên bụng, xung quanh các lỗ thông hơi và phía vùng bụng của đuôi. Màu đỏ: thương ở trên cổ họng, chóp ngực và ngực. Đen và màu vừng: thường là một dấu tam giác trên cả hai bên của chóp ngực.\n",
    "Shiba có xu hướng thể hiện tính tự lập và đôi khi còn hung hăng. Shiba Inu tốt nhất nên được nuôi trong một gia đình mà không có những con chó nhỏ khác hay trẻ em, nhưng huấn luyện vâng lời vẫn có thể được và xã hội sớm có thể làm cho tất cả trở nên ngoan ngoãn. Giống chó cũng tương tác khá tốt với mèo.\n",
    "Một tinh thần mạnh dạn, một bản chất tốt đẹp và sự thẳng thắn không lẫn lộn mang lại phẩm giá và vẻ đẹp tự nhiên. Shiba có tính chất tự lập và có thể dè dặt đối với người lạ nhưng lại trung thành và tình cảm với những người có được sự tôn trọng của nó. Nó có thể hung dữ với những con chó khác.\n",
    "Shiba là một giống chó tương đối khó tính và cảm thấy rất cần thiết khi giữ chính nó thật sạch. Nó thường liếm bàn chân giống như mèo, thường di chuyển theo cách riêng của mình để giữ bộ lông sạch sẽ, nhưng lại cực kỳ thích bơi lội và chơi đùa trong các vũng nước. Vì bản chất khó tính và đầy kiêu hãnh vốn có, Shiba con rất dễ dạy dỗ và trong nhiều trường hợp sẽ tự dạy dỗ chính mình. Chỉ cần chủ đơn giản là đặt chúng ra ngoài sau giờ ăn và ngủ thì có thể nói là đã đủ để dạy Shiba phương pháp thích hợp để đi vệ sinh.\n",
    "Một đặc điểm giúp phân biệt giống chó này là \"Shiba scream\". Khi đủ kích động hay không vui, nó sẽ phát ra một tiếng thét lớn và cao. Điều này có thể xảy ra khi nó cố gắng để xử lý con chó theo một cách mà nó cho là không thể chấp nhận được. Các động vật khác cũng có thể phát ra âm thanh tương tự như trong những lúc vui, chẳng hạn như sự trở lại của chủ nhân sau khi vắng mặt lâu ngày hay sự xuất hiện của một người khách yêu thích,...\n",
    "Thí nghiệm phân tích DNA gần đây đã khẳng định rằng loài chó mõm nhọn châu Á này là một trong những giống chó lâu đời nhất, đã sống từ thế kỷ thứ 3 trước Công nguyên.\n",
    "Ban đầu, Shiba Inu được nuôi để săn và bắt các con vật nhỏ, chẳng hạn như các loài chim và thỏ. Dù đã có nhiều nỗ lực để bảo tồn giống, Shiba gần bị tuyệt chủng trong Chiến tranh thế giới thứ hai do tình trạng thiếu thực phẩm cộng thêm dịch bệnh chó sau chiến tranh. Tất cả những con chó sau này được tạo ra chỉ từ ba dòng máu còn sống sót. Những dòng máu đó là Shinshu Shiba từ Nagano, Mino Shiba từ Gifu, và San'in Shiba từ Tottori và Shimane. Shinshu Shiba sở hữu một lớp lông tơ rắn, với một lớp lông dày bảo vệ, nhỏ và có màu đỏ. Mino Shiba thường có đôi tai dày, nhọn và sở hữu một cái đuôi hình lưỡi liềm, chứ không phải là đuôi cuộn tròn thường được tìm thấy trên Shiba hiện nay. San'in Shiba thì lớn hơn so với hầu hết các giống Shiba hiện nay, và thường có màu đen, không có dấu sẫm và trắng thường được tìm thấy trên Shiba đen - sẫm hiện nay. Khi nghiên cứu về chó Nhật được chính thức hóa trong đầu và giữa thế kỷ 20, ba chủng này đã được kết hợp thành một giống tổng thể, Shiba Inu. Các tiêu chuẩn giống Nhật Bản đầu tiên cho Shiba, tiêu chuẩn Nippo, được xuất bản vào năm 1934. Vào tháng 12 năm 1936, các Shiba Inu được công nhận là Di tích tự nhiên của Nhật Bản thông qua Đạo luật văn hóa, phần lớn là do những nỗ lực của Nippo (Nihon Ken Hozonkai) - Hiệp hội Bảo tồn Chó Nhật Bản.\n",
    "Năm 1954, một gia đình phục vụ vũ trang mang con Shiba Inu đầu tiên đến Hoa Kỳ. Vào năm 1979, lứa đầu tiên được ghi nhận sinh ra tại Hoa Kỳ. Shiba đã được công nhận bởi Hiệp hội chó giống Mỹ vào năm 1992 và được bổ sung vào nhóm AKC (nhóm phi thể thao) vào năm 1993. Giống bây giờ chủ yếu được nuôi như thú cưng ở Nhật Bản và các nước khác.\n",
    "Một con Shina Inu đang chơi đùa ở bãi cỏ.\n",
    "Tình trạng sức khỏe được biết ảnh hưởng đến giống chó này là dị ứng, thanh quang nhãn, cườm thủy tinh thể mắt, loạn sản xương hông, quặp và trật xương bánh chè. Nhìn chung, dù gì đi nữa, chúng có tính di truyền cao và khá nhiều Shiba được chẩn đoán khuyết tật do di truyền so với các giống chó khác.\n",
    "Kiểm tra chung định kỳ được khuyến cáo nên được thực hiện trong suốt cuộc đời của con chó nhưng vấn đề thường được phát hiện sớm trong cuộc đời của nó. Kiểm tra mắt nên được thực hiện hàng năm vì vấn đề về mắt có thể phát triển theo thời gian. Năm hai tuổi, Shiba Inu có thể được coi là hoàn toàn tự do khỏi các vấn đề chung nếu không được phát hiện bởi thời điểm này, vì ở độ tuổi này bộ xương đã được phát triển đầy đủ.\n",
    "Như đối với bất kỳ những con chó khác, Shiba nên được đi hoặc nếu không thì nên vận động hàng ngày.\n",
    "Tuổi thọ trung bình của Shiba Inu là từ 12 đến 16 năm. Tập thể dục, đặc biệt là đi bộ mỗi ngày, sẽ giúp cho giống chó này sống lâu và khỏe mạnh. Shiba lâu đời nhất được biết đến là \"Pusuke\", đã qua đời ở tuổi 26 vào đầu tháng 12 năm 2011 và là chú chó già nhất còn sống vào thời điểm đó.\n",
    "Giống chó này rất sạch sẽ, vì vậy nhu cầu chải chuốt nên được thực hiện tối thiểu. Một lớp lông Shiba Inu thô, ngắn có chiều dài trung bình với lớp lông bên ngoài dài 2,5 đến 3,2 cm (1 đến 1 1⁄4 in); và không thấm nước tự nhiên nên ít cần tắm thường xuyên. Nó cũng có một lớp lông dày có thể bảo vệ chúng khỏi nhiệt độ đông đá. Tuy nhiên, rụng lông có thể là một mối phiền toái. Rụng lông nặng nhất có sự thay đổi theo mùa và đặc biệt là trong mùa hè, nhưng việc chải lông hàng ngày có thể làm giảm vấn đề này. Chủ nhân không được phép cạo hoặc cắt lông của Shiba Inu, vì lông cần thiết để bảo vệ chó khỏi nhiệt độ cả nóng lẫn lạnh.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:48:59.399137Z",
     "start_time": "2021-07-22T05:48:47.838549Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shiba Inu (柴犬 (sài khuyển)) là loại chó nhỏ nhất trong sáu giống chó nguyên thủy và riêng biệt đến từ Nhật Bản. Điều này khiến cho một số người tin rằng Shiba được đặt tên như thế là vì loài chó này được sử dụng để săn mồi trong các bụi cây, hoặc có thể là do màu sắc phổ biến nhất của Shiba Inu là màu đỏ tương tự như của các cây bụi. Đối với con cái là 33 đến 41 cm (13 đến 16 in). Shiba có thể có màu đỏ, đen và nâu, hoặc màu vừng (màu đỏ với những sợi ngã sang đen), với một lớp lông lót màu kem, màu da bò, hoặc màu xám. Urajiro (màu kem trắng) có ở các bộ phận sau trên tất cả các vùng lông: ở hai bên mõm, trên má, bên trong tai, trên hàm dưới và ở chỗ cổ họng, bên trong chân, trên bụng, xung quanh các lỗ thông hơi và phía vùng bụng của đuôi. Shiba có tính chất tự lập và có thể dè dặt đối với người lạ nhưng lại trung thành và tình cảm với những người có được sự tôn trọng của nó. Nó có thể hung dữ với những con chó khác. Khi nghiên cứu về chó Nhật được chính thức hóa trong đầu và giữa thế kỷ 20, ba chủng này đã được kết hợp thành một giống tổng thể, Shiba Inu. Nhìn chung, dù gì đi nữa, chúng có tính di truyền cao và khá nhiều Shiba được chẩn đoán khuyết tật do di truyền so với các giống chó khác. Tuy nhiên, rụng lông có thể là một mối phiền toái.\n"
     ]
    }
   ],
   "source": [
    "#default model with number of senteces = 10\n",
    "model = Summarizer()\n",
    "result = model(body, num_sentences = 10)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:47:07.735002Z",
     "start_time": "2021-07-22T05:46:35.772266Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shiba Inu (柴犬 (sài khuyển)) là loại chó nhỏ nhất trong sáu giống chó nguyên thủy và riêng biệt đến từ Nhật Bản. Tuy nhiên, trong một phương ngữ Nagano cổ, từ Shiba cũng có ý nghĩa là nhỏ, do đó cái tên có thể nói đến tầm vóc nhỏ bé của con chó. Khung hình của Shiba nhỏ gọn với cơ bắp phát triển tốt. Một tinh thần mạnh dạn, một bản chất tốt đẹp và sự thẳng thắn không lẫn lộn mang lại phẩm giá và vẻ đẹp tự nhiên. Nó có thể hung dữ với những con chó khác. Nó thường liếm bàn chân giống như mèo, thường di chuyển theo cách riêng của mình để giữ bộ lông sạch sẽ, nhưng lại cực kỳ thích bơi lội và chơi đùa trong các vũng nước. Vì bản chất khó tính và đầy kiêu hãnh vốn có, Shiba con rất dễ dạy dỗ và trong nhiều trường hợp sẽ tự dạy dỗ chính mình. Giống bây giờ chủ yếu được nuôi như thú cưng ở Nhật Bản và các nước khác. Tập thể dục, đặc biệt là đi bộ mỗi ngày, sẽ giúp cho giống chó này sống lâu và khỏe mạnh. Giống chó này rất sạch sẽ, vì vậy nhu cầu chải chuốt nên được thực hiện tối thiểu. Nó cũng có một lớp lông dày có thể bảo vệ chúng khỏi nhiệt độ đông đá.\n"
     ]
    }
   ],
   "source": [
    "#BERT large Uncased model with number of senteces = 10\n",
    "model = Summarizer(model = 'bert-large-uncased')\n",
    "result = model(body, num_sentences = 10)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:47:41.476382Z",
     "start_time": "2021-07-22T05:47:07.762908Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shiba Inu (柴犬 (sài khuyển)) là loại chó nhỏ nhất trong sáu giống chó nguyên thủy và riêng biệt đến từ Nhật Bản. Inu hoặc ken (犬 - Hán Việt: khuyển) trong tiếng Nhật có nghĩa là con chó, nhưng nguồn gốc của từ \"Shiba\" vẫn chưa rõ. Khung hình của Shiba nhỏ gọn với cơ bắp phát triển tốt. Đối với con cái là 33 đến 41 cm (13 đến 16 in). Giống chó cũng tương tác khá tốt với mèo. Nó có thể hung dữ với những con chó khác. Nó thường liếm bàn chân giống như mèo, thường di chuyển theo cách riêng của mình để giữ bộ lông sạch sẽ, nhưng lại cực kỳ thích bơi lội và chơi đùa trong các vũng nước. Vì bản chất khó tính và đầy kiêu hãnh vốn có, Shiba con rất dễ dạy dỗ và trong nhiều trường hợp sẽ tự dạy dỗ chính mình. Một đặc điểm giúp phân biệt giống chó này là \"Shiba scream\". Những dòng máu đó là Shinshu Shiba từ Nagano, Mino Shiba từ Gifu, và San'in Shiba từ Tottori và Shimane. San'in Shiba thì lớn hơn so với hầu hết các giống Shiba hiện nay, và thường có màu đen, không có dấu sẫm và trắng thường được tìm thấy trên Shiba đen - sẫm hiện nay. Vào năm 1979, lứa đầu tiên được ghi nhận sinh ra tại Hoa Kỳ. Giống bây giờ chủ yếu được nuôi như thú cưng ở Nhật Bản và các nước khác. Kiểm tra chung định kỳ được khuyến cáo nên được thực hiện trong suốt cuộc đời của con chó nhưng vấn đề thường được phát hiện sớm trong cuộc đời của nó. Năm hai tuổi, Shiba Inu có thể được coi là hoàn toàn tự do khỏi các vấn đề chung nếu không được phát hiện bởi thời điểm này, vì ở độ tuổi này bộ xương đã được phát triển đầy đủ. Như đối với bất kỳ những con chó khác, Shiba nên được đi hoặc nếu không thì nên vận động hàng ngày. Tập thể dục, đặc biệt là đi bộ mỗi ngày, sẽ giúp cho giống chó này sống lâu và khỏe mạnh. Giống chó này rất sạch sẽ, vì vậy nhu cầu chải chuốt nên được thực hiện tối thiểu. Nó cũng có một lớp lông dày có thể bảo vệ chúng khỏi nhiệt độ đông đá. Tuy nhiên, rụng lông có thể là một mối phiền toái. Rụng lông nặng nhất có sự thay đổi theo mùa và đặc biệt là trong mùa hè, nhưng việc chải lông hàng ngày có thể làm giảm vấn đề này.\n"
     ]
    }
   ],
   "source": [
    "#BERT large Uncased model with ratio = 0.3\n",
    "model = Summarizer(model = 'bert-large-uncased')\n",
    "result = model(body, ratio = 0.3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:48:18.093033Z",
     "start_time": "2021-07-22T05:47:41.502313Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shiba Inu (柴犬 (sài khuyển)) là loại chó nhỏ nhất trong sáu giống chó nguyên thủy và riêng biệt đến từ Nhật Bản. Chúng là một giống chó nhỏ, nhanh nhẹn và thích hợp với địa hình miền núi, Shiba Inu ban đầu được nuôi để săn bắt. Inu hoặc ken (犬 - Hán Việt: khuyển) trong tiếng Nhật có nghĩa là con chó, nhưng nguồn gốc của từ \"Shiba\" vẫn chưa rõ. Khung hình của Shiba nhỏ gọn với cơ bắp phát triển tốt. Con đực có chiều cao từ 35 đến 43 cm (14 đến 17 in). Trọng lượng trung bình ở kích thước tương thích là khoảng 10 kg (22 lb) đối với con đực và 8 kg (18 lb) đối với con cái. Giống chó cũng tương tác khá tốt với mèo. Nó có thể hung dữ với những con chó khác. Nó thường liếm bàn chân giống như mèo, thường di chuyển theo cách riêng của mình để giữ bộ lông sạch sẽ, nhưng lại cực kỳ thích bơi lội và chơi đùa trong các vũng nước. Một đặc điểm giúp phân biệt giống chó này là \"Shiba scream\". Khi đủ kích động hay không vui, nó sẽ phát ra một tiếng thét lớn và cao. Năm 1954, một gia đình phục vụ vũ trang mang con Shiba Inu đầu tiên đến Hoa Kỳ. Vào năm 1979, lứa đầu tiên được ghi nhận sinh ra tại Hoa Kỳ. Giống bây giờ chủ yếu được nuôi như thú cưng ở Nhật Bản và các nước khác. Kiểm tra chung định kỳ được khuyến cáo nên được thực hiện trong suốt cuộc đời của con chó nhưng vấn đề thường được phát hiện sớm trong cuộc đời của nó. Năm hai tuổi, Shiba Inu có thể được coi là hoàn toàn tự do khỏi các vấn đề chung nếu không được phát hiện bởi thời điểm này, vì ở độ tuổi này bộ xương đã được phát triển đầy đủ. Như đối với bất kỳ những con chó khác, Shiba nên được đi hoặc nếu không thì nên vận động hàng ngày. Tập thể dục, đặc biệt là đi bộ mỗi ngày, sẽ giúp cho giống chó này sống lâu và khỏe mạnh. Giống chó này rất sạch sẽ, vì vậy nhu cầu chải chuốt nên được thực hiện tối thiểu. Tuy nhiên, rụng lông có thể là một mối phiền toái. Rụng lông nặng nhất có sự thay đổi theo mùa và đặc biệt là trong mùa hè, nhưng việc chải lông hàng ngày có thể làm giảm vấn đề này.\n"
     ]
    }
   ],
   "source": [
    "#default model with CoreferenceHandler\n",
    "model = Summarizer(model = 'bert-large-uncased', sentence_handler=CoreferenceHandler())\n",
    "result = model(body, ratio = 0.3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:50:27.372771Z",
     "start_time": "2021-07-22T05:50:08.993668Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shiba Inu (柴犬 (sài khuyển)) là loại chó nhỏ nhất trong sáu giống chó nguyên thủy và riêng biệt đến từ Nhật Bản. Từ Shiba (柴 - Hán Việt: sài) có nghĩa là cây bụi trong tiếng Nhật, đề cập đến một loại cây hoặc cây bụi có lá chuyển sang màu đỏ vào mùa thu. Điều này khiến cho một số người tin rằng Shiba được đặt tên như thế là vì loài chó này được sử dụng để săn mồi trong các bụi cây, hoặc có thể là do màu sắc phổ biến nhất của Shiba Inu là màu đỏ tương tự như của các cây bụi. Khung hình của Shiba nhỏ gọn với cơ bắp phát triển tốt. Trọng lượng trung bình ở kích thước tương thích là khoảng 10 kg (22 lb) đối với con đực và 8 kg (18 lb) đối với con cái. Lớp lông: Có hai lớp lông với lớp ngoài cứng và thẳng cùng một lớp trong mềm mại và dày. Màu đỏ: thương ở trên cổ họng, chóp ngực và ngực. Shiba có xu hướng thể hiện tính tự lập và đôi khi còn hung hăng. Shiba Inu tốt nhất nên được nuôi trong một gia đình mà không có những con chó nhỏ khác hay trẻ em, nhưng huấn luyện vâng lời vẫn có thể được và xã hội sớm có thể làm cho tất cả trở nên ngoan ngoãn. Giống chó cũng tương tác khá tốt với mèo. Nó có thể hung dữ với những con chó khác. Shiba là một giống chó tương đối khó tính và cảm thấy rất cần thiết khi giữ chính nó thật sạch. Năm 1954, một gia đình phục vụ vũ trang mang con Shiba Inu đầu tiên đến Hoa Kỳ. Giống bây giờ chủ yếu được nuôi như thú cưng ở Nhật Bản và các nước khác. Một con Shina Inu đang chơi đùa ở bãi cỏ. Tình trạng sức khỏe được biết ảnh hưởng đến giống chó này là dị ứng, thanh quang nhãn, cườm thủy tinh thể mắt, loạn sản xương hông, quặp và trật xương bánh chè. Nhìn chung, dù gì đi nữa, chúng có tính di truyền cao và khá nhiều Shiba được chẩn đoán khuyết tật do di truyền so với các giống chó khác. Năm hai tuổi, Shiba Inu có thể được coi là hoàn toàn tự do khỏi các vấn đề chung nếu không được phát hiện bởi thời điểm này, vì ở độ tuổi này bộ xương đã được phát triển đầy đủ. Tập thể dục, đặc biệt là đi bộ mỗi ngày, sẽ giúp cho giống chó này sống lâu và khỏe mạnh. Nó cũng có một lớp lông dày có thể bảo vệ chúng khỏi nhiệt độ đông đá. Tuy nhiên, rụng lông có thể là một mối phiền toái.\n"
     ]
    }
   ],
   "source": [
    "model = Summarizer(model = 'xlnet-base-cased', sentence_handler=CoreferenceHandler())\n",
    "result = model(body, ratio = 0.3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:52:13.079809Z",
     "start_time": "2021-07-22T05:52:02.404352Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06264511, -0.04616188,  0.30910435, ..., -0.11081592,\n",
       "        -0.06871919,  0.11080622],\n",
       "       [ 0.0010872 , -0.0021876 ,  0.04671476, ...,  0.42539126,\n",
       "        -0.261949  ,  0.09410372],\n",
       "       [-0.03221155, -0.21116859,  0.19516714, ..., -0.12356774,\n",
       "        -0.13606201,  0.36228496],\n",
       "       ...,\n",
       "       [-0.4348117 ,  0.3021262 ,  0.21845956, ..., -0.6307475 ,\n",
       "        -0.06835769, -0.02482057],\n",
       "       [-0.21573763,  0.32624435, -0.06969851, ..., -0.20903395,\n",
       "        -0.34038976, -0.0154977 ],\n",
       "       [-0.18740307, -0.29025468, -0.01592006, ..., -0.175454  ,\n",
       "         0.24482788,  0.2545929 ]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.run_embeddings(body, ratio=0.3)  # Will return (num_sentences +1, N) embedding numpy matrix.\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:52:35.121139Z",
     "start_time": "2021-07-22T05:52:29.509356Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2692.918701171875,\n",
       " 2500.3896484375,\n",
       " 2321.54345703125,\n",
       " 2202.852783203125,\n",
       " 2082.740966796875,\n",
       " 2033.31689453125,\n",
       " 1945.07568359375,\n",
       " 1863.1490478515625,\n",
       " 1775.525390625]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.calculate_elbow(body, k_max=10)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:52:40.701998Z",
     "start_time": "2021-07-22T05:52:35.153047Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.calculate_optimal_k(body, k_max=10)\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
